Using config: configs/x16_base_config.json
Running GEMM tests...
Test 1: M=1024, K=12288, N=12288
compute module:
simdram config: 8channels x 32ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 13107.2GB/s
simdram internal bw: 4739326.553672316GB/s
simdram ops: 2368.7223119347013Tops
memory capacity: 1024.0GB
peripheral area: 2113.579418320765mm^2
dram area: 33792.0mm^2

memory module: N/A
io module: N/A
Running mapping search...
find_simdram_mapping: Best mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M: RB  N: A  K: CDS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
Running simulation...
--- Input Matmul Size --- M:1024, K:12288, N:12288
Maximum Array Tile Size: {'M': 2, 'K': 192, 'N': 768}
get_arr_tile_stats: arr_latency=0.00028328399999999997, capacity_utilization=0.666015625
get_tile_stats: K_reduction_latency: 5.456e-05 = 715128832 / 13107200000000.0
RB CDS ['A'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
12582912 = 1024 * 12288 * 1
get_tile_io_latency: data_volume=12582912, dup=['A'], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=9.6e-07 = 12582912 / 13107200000000.0
get_tile_stats: tile_size: {'M': 1024, 'K': 12288, 'N': 10912}, arr_tile_size: {'M': 2, 'K': 192, 'N': 682}, MK_dup: 1, KN_dup:1, MN_dup:192, M_K_io_latency: 9.6e-07, K_N_io_latency: 0, M_N_io_latency: 0.00016368, tile_compute_latency:0.00033784399999999996 = 0.00028328399999999997(arr_latency) + 5.456e-05(K_reduction_latency)
get_arr_tile_stats: arr_latency=3.60632e-05, capacity_utilization=0.083984375
get_tile_stats: K_reduction_latency: 6.88e-06 = 90177536 / 13107200000000.0
RB CDS ['A'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
12582912 = 1024 * 12288 * 1
get_tile_io_latency: data_volume=12582912, dup=['A'], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=9.6e-07 = 12582912 / 13107200000000.0
get_tile_stats: tile_size: {'M': 1024, 'K': 12288, 'N': 1376}, arr_tile_size: {'M': 2, 'K': 192, 'N': 86}, MK_dup: 1, KN_dup:1, MN_dup:192, M_K_io_latency: 9.6e-07, K_N_io_latency: 0, M_N_io_latency: 2.064e-05, tile_compute_latency:4.29432e-05 = 3.60632e-05(arr_latency) + 6.88e-06(K_reduction_latency)
================ Strategy Summary ================
Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M: RB  N: A  K: CDS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)

---------------- Tile Sizes ----------------------
| Tile_M      | Tile_N      | Tile_K      |
|-------------|-------------|-------------|
| 1024        | 10912       | 12288       |

| Arr_Tile_M  | Arr_Tile_N  | Arr_Tile_K  |
|-------------|-------------|-------------|
| 2           | 682         | 192         |

--------------- Utilization ----------------------
| Row         | Col         | Array       | Bank        | Device      | Rank        | Channel     |
|-------------|-------------|-------------|-------------|-------------|-------------|-------------|
| 0.666015625 | 0.1875      | 1           | 1           | 1           | 1           | 1           |

------------------ Latency -----------------------
| Total Latency        | 0.0005867072           cycles|
| Total Compute Latency | 0.00038078719999999996 cycles|
| Total Array Latency  | 0.00031934719999999995 cycles|
| Total Reduction Latency| 6.144e-05              cycles|
| IO Latency           | 0.00020591999999999998 cycles|

----------- Hardware Requirements ---------------
| col_multicast        | False                 |
| col_broadcast        | False                 |
| broadcast            | {'C': False, 'R': False, 'B': False, 'A': True, 'S': False, 'D': False}|
| reduction            | {'C': True, 'R': False, 'B': False, 'A': False, 'S': True, 'D': True}|
==================================================

---------------- Debug Info -----------------------
| Remaining Tiles       |                         |
|-----------------------|-------------------------|
| M_remain              | 0                      |
| N_remain              | 1376                   |
| K_remain              | 0                      |

| Fully Partitioned #Tiles |                       |
|-------------------------|-----------------------|
| M_t                   | 1                      |
| N_t                   | 1                      |
| K_t                   | 1                      |

|------------------------|------------------------|
==================================================
Tiling utilization: {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
Column utilization: 0.1875
Capacity utilization: 0.666015625
GEMM 1024x12288x12288 latency: 0.0005867072s
simulated latency: GEMM_1024x12288x12288 0.0005867072
roofline_model_simdram: total_ops=309237645312, total_data_movement=25165824, peak_flops=2368722311934701.0, bandwidth=13107200000000.0
roofline_model_simdram: compute_bound_time=0.0001305504, memory_bound_time=1.92e-06
GEMM roofline latency: 0.0001305504ms
Results written to test_gemm_x16_base_config.json_1024_12288_12288_simdram_ddr5_operandocality.csv
Test 2: M=2048, K=24576, N=24576
compute module:
simdram config: 8channels x 32ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 13107.2GB/s
simdram internal bw: 4739326.553672316GB/s
simdram ops: 2368.7223119347013Tops
memory capacity: 1024.0GB
peripheral area: 2113.579418320765mm^2
dram area: 33792.0mm^2

memory module: N/A
io module: N/A
Running mapping search...
find_simdram_mapping: Best mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M: BA  N: R  K: CDS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
Running simulation...
--- Input Matmul Size --- M:2048, K:24576, N:24576
Maximum Array Tile Size: {'M': 8, 'K': 384, 'N': 768}
get_arr_tile_stats: arr_latency=0.00037536959999999995, capacity_utilization=0.8828125
get_tile_stats: K_reduction_latency: 7.232e-05 = 947912704 / 13107200000000.0
BA CDS ['R'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
50331648 = 2048 * 24576 * 1
get_tile_io_latency: data_volume=1610612736, dup=[], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=0.00012288 = 1610612736 / 13107200000000.0
get_tile_stats: tile_size: {'M': 2048, 'K': 24576, 'N': 7232}, arr_tile_size: {'M': 8, 'K': 384, 'N': 226}, MK_dup: 1, KN_dup:1, MN_dup:384, M_K_io_latency: 0.00012288, K_N_io_latency: 0, M_N_io_latency: 0.00043391999999999997, tile_compute_latency:0.00044768959999999996 = 0.00037536959999999995(arr_latency) + 7.232e-05(K_reduction_latency)
get_arr_tile_stats: arr_latency=0.0001497184, capacity_utilization=0.3515625
get_tile_stats: K_reduction_latency: 2.88e-05 = 377487360 / 13107200000000.0
BA CDS ['R'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
50331648 = 2048 * 24576 * 1
get_tile_io_latency: data_volume=1610612736, dup=[], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=0.00012288 = 1610612736 / 13107200000000.0
get_tile_stats: tile_size: {'M': 2048, 'K': 24576, 'N': 2880}, arr_tile_size: {'M': 8, 'K': 384, 'N': 90}, MK_dup: 1, KN_dup:1, MN_dup:384, M_K_io_latency: 0.00012288, K_N_io_latency: 0, M_N_io_latency: 0.0001728, tile_compute_latency:0.0001785184 = 0.0001497184(arr_latency) + 2.88e-05(K_reduction_latency)
================ Strategy Summary ================
Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M: BA  N: R  K: CDS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)

---------------- Tile Sizes ----------------------
| Tile_M      | Tile_N      | Tile_K      |
|-------------|-------------|-------------|
| 2048        | 7232        | 24576       |

| Arr_Tile_M  | Arr_Tile_N  | Arr_Tile_K  |
|-------------|-------------|-------------|
| 8           | 226         | 384         |

--------------- Utilization ----------------------
| Row         | Col         | Array       | Bank        | Device      | Rank        | Channel     |
|-------------|-------------|-------------|-------------|-------------|-------------|-------------|
| 0.8828125   | 0.375       | 1           | 1           | 1           | 1           | 1           |

------------------ Latency -----------------------
| Total Latency        | 0.0032918272           cycles|
| Total Compute Latency | 0.0015215871999999999  cycles|
| Total Array Latency  | 0.0012758271999999998  cycles|
| Total Reduction Latency| 0.00024576             cycles|
| IO Latency           | 0.0017702400000000002  cycles|

----------- Hardware Requirements ---------------
| col_multicast        | False                 |
| col_broadcast        | False                 |
| broadcast            | {'C': False, 'R': True, 'B': False, 'A': False, 'S': False, 'D': False}|
| reduction            | {'C': True, 'R': False, 'B': False, 'A': False, 'S': True, 'D': True}|
==================================================

---------------- Debug Info -----------------------
| Remaining Tiles       |                         |
|-----------------------|-------------------------|
| M_remain              | 0                      |
| N_remain              | 2880                   |
| K_remain              | 0                      |

| Fully Partitioned #Tiles |                       |
|-------------------------|-----------------------|
| M_t                   | 1                      |
| N_t                   | 3                      |
| K_t                   | 1                      |

|------------------------|------------------------|
==================================================
Tiling utilization: {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
Column utilization: 0.375
Capacity utilization: 0.8828125
GEMM 2048x24576x24576 latency: 0.0032918272s
simulated latency: GEMM_2048x24576x24576 0.0032918272
roofline_model_simdram: total_ops=2473901162496, total_data_movement=100663296, peak_flops=2368722311934701.0, bandwidth=13107200000000.0
roofline_model_simdram: compute_bound_time=0.0010444032, memory_bound_time=7.68e-06
GEMM roofline latency: 0.0010444032ms
Results written to test_gemm_x16_base_config.json_2048_24576_24576_simdram_ddr5_operandocality.csv
Test 3: M=1, K=12288, N=12288
compute module:
simdram config: 8channels x 32ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 13107.2GB/s
simdram internal bw: 4739326.553672316GB/s
simdram ops: 2368.7223119347013Tops
memory capacity: 1024.0GB
peripheral area: 2113.579418320765mm^2
dram area: 33792.0mm^2

memory module: N/A
io module: N/A
Running mapping search...
find_simdram_mapping: Best mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: CRA  K: BDS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
Running simulation...
--- Input Matmul Size --- M:1, K:12288, N:12288
Maximum Array Tile Size: {'M': 1, 'K': 96, 'N': 3}
get_arr_tile_stats: arr_latency=1.0125999999999998e-06, capacity_utilization=0.00146484375
get_tile_stats: K_reduction_latency: 1.2e-07 = 1572864 / 13107200000000.0
 BDS ['C', 'R', 'A'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
12288 = 1 * 12288 * 1
get_tile_io_latency: data_volume=3145728, dup=['A'], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=2.4e-07 = 3145728 / 13107200000000.0
get_tile_stats: tile_size: {'M': 1, 'K': 12288, 'N': 12288}, arr_tile_size: {'M': 1, 'K': 96, 'N': 3}, MK_dup: 1, KN_dup:1, MN_dup:96, M_K_io_latency: 2.4e-07, K_N_io_latency: 0, M_N_io_latency: 8.999999999999999e-08, tile_compute_latency:1.1325999999999998e-06 = 1.0125999999999998e-06(arr_latency) + 1.2e-07(K_reduction_latency)
================ Strategy Summary ================
Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: CRA  K: BDS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)

---------------- Tile Sizes ----------------------
| Tile_M      | Tile_N      | Tile_K      |
|-------------|-------------|-------------|
| 1           | 12288       | 12288       |

| Arr_Tile_M  | Arr_Tile_N  | Arr_Tile_K  |
|-------------|-------------|-------------|
| 1           | 3           | 96          |

--------------- Utilization ----------------------
| Row         | Col         | Array       | Bank        | Device      | Rank        | Channel     |
|-------------|-------------|-------------|-------------|-------------|-------------|-------------|
| 0.00146484375 | 0.09375     | 1           | 1           | 1           | 1           | 1           |

------------------ Latency -----------------------
| Total Latency        | 1.5525999999999998e-06 cycles|
| Total Compute Latency | 1.1325999999999998e-06 cycles|
| Total Array Latency  | 1.0125999999999998e-06 cycles|
| Total Reduction Latency| 1.2e-07                cycles|
| IO Latency           | 4.1999999999999995e-07 cycles|

----------- Hardware Requirements ---------------
| col_multicast        | False                 |
| col_broadcast        | False                 |
| broadcast            | {'C': True, 'R': True, 'B': False, 'A': True, 'S': False, 'D': False}|
| reduction            | {'C': False, 'R': False, 'B': True, 'A': False, 'S': True, 'D': True}|
==================================================

---------------- Debug Info -----------------------
| Remaining Tiles       |                         |
|-----------------------|-------------------------|
| M_remain              | 0                      |
| N_remain              | 0                      |
| K_remain              | 0                      |

| Fully Partitioned #Tiles |                       |
|-------------------------|-----------------------|
| M_t                   | 1                      |
| N_t                   | 1                      |
| K_t                   | 1                      |

|------------------------|------------------------|
==================================================
Tiling utilization: {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
Column utilization: 0.09375
Capacity utilization: 0.00146484375
GEMM 1x12288x12288 latency: 1.5525999999999998e-06s
simulated latency: GEMM_1x12288x12288 1.5525999999999998e-06
roofline_model_simdram: total_ops=301989888, total_data_movement=24576, peak_flops=2368722311934701.0, bandwidth=13107200000000.0
roofline_model_simdram: compute_bound_time=1.27490625e-07, memory_bound_time=1.875e-09
GEMM roofline latency: 1.27490625e-07ms
Results written to test_gemm_x16_base_config.json_1_12288_12288_simdram_ddr5_operandocality.csv
Test 4: M=1, K=24576, N=24576
compute module:
simdram config: 8channels x 32ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 13107.2GB/s
simdram internal bw: 4739326.553672316GB/s
simdram ops: 2368.7223119347013Tops
memory capacity: 1024.0GB
peripheral area: 2113.579418320765mm^2
dram area: 33792.0mm^2

memory module: N/A
io module: N/A
Running mapping search...
find_simdram_mapping: Best mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: CRA  K: BDS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
Running simulation...
--- Input Matmul Size --- M:1, K:24576, N:24576
Maximum Array Tile Size: {'M': 1, 'K': 192, 'N': 6}
get_arr_tile_stats: arr_latency=1.6348e-06, capacity_utilization=0.0029296875
get_tile_stats: K_reduction_latency: 2.4e-07 = 3145728 / 13107200000000.0
 BDS ['C', 'R', 'A'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
24576 = 1 * 24576 * 1
get_tile_io_latency: data_volume=6291456, dup=['A'], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=4.8e-07 = 6291456 / 13107200000000.0
get_tile_stats: tile_size: {'M': 1, 'K': 24576, 'N': 24576}, arr_tile_size: {'M': 1, 'K': 192, 'N': 6}, MK_dup: 1, KN_dup:1, MN_dup:192, M_K_io_latency: 4.8e-07, K_N_io_latency: 0, M_N_io_latency: 3.5999999999999994e-07, tile_compute_latency:1.8748e-06 = 1.6348e-06(arr_latency) + 2.4e-07(K_reduction_latency)
================ Strategy Summary ================
Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: CRA  K: BDS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)

---------------- Tile Sizes ----------------------
| Tile_M      | Tile_N      | Tile_K      |
|-------------|-------------|-------------|
| 1           | 24576       | 24576       |

| Arr_Tile_M  | Arr_Tile_N  | Arr_Tile_K  |
|-------------|-------------|-------------|
| 1           | 6           | 192         |

--------------- Utilization ----------------------
| Row         | Col         | Array       | Bank        | Device      | Rank        | Channel     |
|-------------|-------------|-------------|-------------|-------------|-------------|-------------|
| 0.0029296875 | 0.1875      | 1           | 1           | 1           | 1           | 1           |

------------------ Latency -----------------------
| Total Latency        | 3.0748e-06             cycles|
| Total Compute Latency | 1.8748e-06             cycles|
| Total Array Latency  | 1.6348e-06             cycles|
| Total Reduction Latency| 2.4e-07                cycles|
| IO Latency           | 1.2e-06                cycles|

----------- Hardware Requirements ---------------
| col_multicast        | False                 |
| col_broadcast        | False                 |
| broadcast            | {'C': True, 'R': True, 'B': False, 'A': True, 'S': False, 'D': False}|
| reduction            | {'C': False, 'R': False, 'B': True, 'A': False, 'S': True, 'D': True}|
==================================================

---------------- Debug Info -----------------------
| Remaining Tiles       |                         |
|-----------------------|-------------------------|
| M_remain              | 0                      |
| N_remain              | 0                      |
| K_remain              | 0                      |

| Fully Partitioned #Tiles |                       |
|-------------------------|-----------------------|
| M_t                   | 1                      |
| N_t                   | 1                      |
| K_t                   | 1                      |

|------------------------|------------------------|
==================================================
Tiling utilization: {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
Column utilization: 0.1875
Capacity utilization: 0.0029296875
GEMM 1x24576x24576 latency: 3.0748e-06s
simulated latency: GEMM_1x24576x24576 3.0748e-06
roofline_model_simdram: total_ops=1207959552, total_data_movement=49152, peak_flops=2368722311934701.0, bandwidth=13107200000000.0
roofline_model_simdram: compute_bound_time=5.099625e-07, memory_bound_time=3.75e-09
GEMM roofline latency: 5.099625e-07ms
Results written to test_gemm_x16_base_config.json_1_24576_24576_simdram_ddr5_operandocality.csv
Running LLM tests...
Testing GPT-3 175B model prefill
Simulate Running on DRAM PIM
compute module:
simdram config: 8channels x 32ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 13107.2GB/s
simdram internal bw: 4739326.553672316GB/s
simdram ops: 2368.7223119347013Tops
memory capacity: 1024.0GB
peripheral area: 2113.579418320765mm^2
dram area: 33792.0mm^2

memory module: N/A
io module: N/A
LLM model: gpt3-175B
simulating qkv: Matmul M=1024, K=12288, N=12288
qkv latency: 0.0017601216, compute latency: 0.00038078719999999996, io overhead: 0.00020591999999999998
simulating q_mul_k: Batched Matmul BS=96 M=1024, K=128, N=1024
Batched Matmul: M=1024, K=128, N=1024, BS=96
BatchedMatmul latency: 6.9888e-06
q_mul_k latency: 6.9888e-06, compute latency: 4.3488e-06, io overhead: 2.64e-06
simulating a_mul_v: Batched Matmul BS=96 M=1024, K=1024, N=128
Batched Matmul: M=1024, K=1024, N=128, BS=96
BatchedMatmul latency: 3.0895999999999996e-06
a_mul_v latency: 3.0895999999999996e-06, compute latency: 2.3695999999999997e-06, io overhead: 7.2e-07
simulating h_matmul0: Matmul M=1024, K=12288, N=12288
h_matmul0 latency: 0.0005867072, compute latency: 0.00038078719999999996, io overhead: 0.00020591999999999998
simulating h1_matmul1: Matmul M=1024, K=12288, N=49152
h1_matmul1 latency: 0.0022385344, compute latency: 0.0007615744, io overhead: 0.0014769599999999998
simulating h2_matmul2: Matmul M=1024, K=49152, N=12288
h2_matmul2 latency: 0.0012018239999999998, compute latency: 0.0007611839999999999, io overhead: 0.00044063999999999996
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 0.0057972656
matmul total latency: 0.0057972656
weighted avg simd utilization: 0.2984804681020652
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 1.0}
gpt3-175B 96 layers prefill latency: 0.5565374975999999
simulated latency: gpt3-175B_prefill 0.5565374975999999
Testing GPT-3 175B model decode
Simulate Running on DRAM PIM
compute module:
simdram config: 8channels x 32ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 13107.2GB/s
simdram internal bw: 4739326.553672316GB/s
simdram ops: 2368.7223119347013Tops
memory capacity: 1024.0GB
peripheral area: 2113.579418320765mm^2
dram area: 33792.0mm^2

memory module: N/A
io module: N/A
simulating qkv: Matmul M=1, K=12288, N=12288
qkv latency: 4.6578e-06, compute latency: 3.397799999999999e-06, io overhead: 1.2599999999999998e-06, kernel launch overhead: 0
simulating q_mul_k:BatchedMatmul BS=96 M=1, K=128, N=1025
Batched Matmul: M=1, K=128, N=1025, BS=96
BatchedMatmul latency: 6.081176879882814e-07
q_mul_k latency: 6.081176879882814e-07, compute latency: 6.028048828125e-07, io overhead: 5.31280517578125e-09, kernel launch overhead: 0
simulating a_mul_v: BatchedMatmul BS=96 M=1, K=1025, N=128
Batched Matmul: M=1, K=1025, N=128, BS=96
BatchedMatmul latency: 6.1034150390625e-07
a_mul_v latency: 6.1034150390625e-07, compute latency: 6.078e-07, io overhead: 2.5415039062499997e-09, kernel launch overhead: 0
simulating h_matmul0: Matmul M=1, K=12288, N=12288
h_matmul0 latency: 1.5525999999999998e-06, compute latency: 1.1325999999999998e-06, io overhead: 4.1999999999999995e-07, kernel launch overhead: 0
simulating h1_matmul1: Matmul M=1, K=12288, N=49152
h1_matmul1 latency: 3.7948e-06, compute latency: 1.8748e-06, io overhead: 1.92e-06, kernel launch overhead: 0
simulating h2_matmul2: Matmul M=1, K=49152, N=12288
h2_matmul2 latency: 2.7148000000000002e-06, compute latency: 1.8748e-06, io overhead: 8.399999999999999e-07, kernel launch overhead: 0
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 1.393845919189453e-05
matmul total latency: 1.393845919189453e-05
weighted avg simd utilization: 0.12950892048088786
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 0.9317104038318894, 'S': 1.0, 'D': 1.0}
transformer latency: 1.393845919189453e-05
gpt3-175B decode latency per token: 1.393845919189453e-05
gpt3-175B decode total latency for 2048 tokens: 2.7404125847999996
simulated latency: gpt3-175B_decode 2.7404125847999996
Testing GPT-3 6.7B model prefill
Simulate Running on DRAM PIM
compute module:
simdram config: 8channels x 32ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 13107.2GB/s
simdram internal bw: 4739326.553672316GB/s
simdram ops: 2368.7223119347013Tops
memory capacity: 1024.0GB
peripheral area: 2113.579418320765mm^2
dram area: 33792.0mm^2

memory module: N/A
io module: N/A
LLM model: gpt3-6.7B
simulating qkv: Matmul M=1024, K=4096, N=4096
qkv latency: 0.0004378944, compute latency: 6.37248e-05, io overhead: 8.224e-05
simulating q_mul_k: Batched Matmul BS=32 M=1024, K=128, N=1024
Batched Matmul: M=1024, K=128, N=1024, BS=32
BatchedMatmul latency: 6.9888e-06
q_mul_k latency: 6.9888e-06, compute latency: 4.3488e-06, io overhead: 2.64e-06
simulating a_mul_v: Batched Matmul BS=32 M=1024, K=1024, N=128
Batched Matmul: M=1024, K=1024, N=128, BS=32
BatchedMatmul latency: 3.0895999999999996e-06
a_mul_v latency: 3.0895999999999996e-06, compute latency: 2.3695999999999997e-06, io overhead: 7.2e-07
simulating h_matmul0: Matmul M=1024, K=4096, N=4096
h_matmul0 latency: 0.0001459648, compute latency: 6.37248e-05, io overhead: 8.224e-05
simulating h1_matmul1: Matmul M=1024, K=4096, N=16384
h1_matmul1 latency: 0.0004184384, compute latency: 0.0002541184, io overhead: 0.00016432
simulating h2_matmul2: Matmul M=1024, K=16384, N=4096
h2_matmul2 latency: 0.0002912896, compute latency: 0.0001274496, io overhead: 0.00016384
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 0.0013036656
matmul total latency: 0.0013036656
weighted avg simd utilization: 0.15212133387580373
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 1.0}
gpt3-6.7B 32 layers prefill latency: 0.0417172992
simulated latency: gpt3-6.7B_prefill 0.0417172992
Testing GPT-3 6.7B model decode
Simulate Running on DRAM PIM
compute module:
simdram config: 8channels x 32ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 13107.2GB/s
simdram internal bw: 4739326.553672316GB/s
simdram ops: 2368.7223119347013Tops
memory capacity: 1024.0GB
peripheral area: 2113.579418320765mm^2
dram area: 33792.0mm^2

memory module: N/A
io module: N/A
simulating qkv: Matmul M=1, K=4096, N=4096
qkv latency: 2.2134000000000003e-06, compute latency: 1.9134e-06, io overhead: 3e-07, kernel launch overhead: 0
simulating q_mul_k:BatchedMatmul BS=32 M=1, K=128, N=1025
Batched Matmul: M=1, K=128, N=1025, BS=32
BatchedMatmul latency: 6.081176879882814e-07
q_mul_k latency: 6.081176879882814e-07, compute latency: 6.028048828125e-07, io overhead: 5.31280517578125e-09, kernel launch overhead: 0
simulating a_mul_v: BatchedMatmul BS=32 M=1, K=1025, N=128
Batched Matmul: M=1, K=1025, N=128, BS=32
BatchedMatmul latency: 6.1034150390625e-07
a_mul_v latency: 6.1034150390625e-07, compute latency: 6.078e-07, io overhead: 2.5415039062499997e-09, kernel launch overhead: 0
simulating h_matmul0: Matmul M=1, K=4096, N=4096
h_matmul0 latency: 7.378000000000001e-07, compute latency: 6.378000000000001e-07, io overhead: 1e-07, kernel launch overhead: 0
simulating h1_matmul1: Matmul M=1, K=4096, N=16384
h1_matmul1 latency: 1.2052e-06, compute latency: 8.851999999999999e-07, io overhead: 3.2e-07, kernel launch overhead: 0
simulating h2_matmul2: Matmul M=1, K=16384, N=4096
h2_matmul2 latency: 1.0378e-06, compute latency: 6.378000000000001e-07, io overhead: 4e-07, kernel launch overhead: 0
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 6.4126591918945315e-06
matmul total latency: 6.4126591918945315e-06
weighted avg simd utilization: 0.04672863380731764
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 0.8515667649041312, 'S': 1.0, 'D': 1.0}
transformer latency: 6.4126591918945315e-06
gpt3-6.7B decode latency per token: 6.4126591918945315e-06
gpt3-6.7B decode total latency for 2048 tokens: 0.4202600328
simulated latency: gpt3-6.7B_decode 0.4202600328
Testing LLaMA 3.1 70B model prefill
Simulate Running on DRAM PIM
compute module:
simdram config: 8channels x 32ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 13107.2GB/s
simdram internal bw: 4739326.553672316GB/s
simdram ops: 2368.7223119347013Tops
memory capacity: 1024.0GB
peripheral area: 2113.579418320765mm^2
dram area: 33792.0mm^2

memory module: N/A
io module: N/A
LLM model: Llama-3.1-70B
simulating q_proj: Matmul M=1024, K=8192, N=8192
q_proj latency: 0.0003974784, compute latency: 0.0002541184, io overhead: 0.00014335999999999998
simulating k_proj: Matmul M=1024, K=8192, N=1024
k_proj latency: 5.31776e-05, compute latency: 3.2057599999999996e-05, io overhead: 2.112e-05
simulating v_proj: Matmul M=1024, K=8192, N=1024
skipping v_proj simulation, using k_proj
v_proj latency: 5.31776e-05, compute latency: 3.2057599999999996e-05, io overhead: 2.112e-05
simulating q_mul_k: Batched_Matmul BS=64 M=1024, K=128, N=1024
Batched Matmul: M=1024, K=128, N=1024, BS=64
BatchedMatmul latency: 6.9888e-06
q_mul_k latency: 6.9888e-06, compute latency: 4.3488e-06, io overhead: 2.64e-06
simulating a_mul_v: Batched_Matmul BS=64 M=1024, K=1024, N=128
Batched Matmul: M=1024, K=1024, N=128, BS=64
BatchedMatmul latency: 3.0895999999999996e-06
a_mul_v latency: 3.0895999999999996e-06, compute latency: 2.3695999999999997e-06, io overhead: 7.2e-07
simulating h_matmul0: Matmul M=1024, K=8192, N=8192
h_matmul0 latency: 0.0003974784, compute latency: 0.0002541184, io overhead: 0.00014335999999999998
simulating h1_matmul1: Matmul M=1024, K=8192, N=28672
h1_matmul1 latency: 0.0011097216, compute latency: 0.00044412159999999995, io overhead: 0.0006655999999999999
simulating h2_matmul2: Matmul M=1024, K=28672, N=8192
h2_matmul2 latency: 0.0006754560000000001, compute latency: 0.000507456, io overhead: 0.00016799999999999996
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 0.0026965680000000003
matmul total latency: 0.0026965680000000003
weighted avg simd utilization: 0.19953368503965035
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 1.0}
Llama-3.1-70B 80 layers prefill latency: 0.21572544000000002
simulated latency: Llama-3.1-70B_prefill 0.21572544000000002
Testing LLaMA 3.1 70B model decode
Simulate Running on DRAM PIM
compute module:
simdram config: 8channels x 32ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 13107.2GB/s
simdram internal bw: 4739326.553672316GB/s
simdram ops: 2368.7223119347013Tops
memory capacity: 1024.0GB
peripheral area: 2113.579418320765mm^2
dram area: 33792.0mm^2

memory module: N/A
io module: N/A
simulating q_proj: Matmul M=1, K=8192, N=8192
q_proj latency: 1.1178000000000001e-06, compute latency: 6.378000000000001e-07, io overhead: 4.8e-07
simulating k_proj: Matmul M=1, K=8192, N=1024
k_proj latency: 6.803000000000001e-07, compute latency: 6.378000000000001e-07, io overhead: 4.2500000000000003e-08
simulating v_proj: Matmul M=1, K=8192, N=1024
skipping v_proj simulation, using k_proj
v_proj latency: 6.803000000000001e-07, compute latency: 6.378000000000001e-07, io overhead: 4.2500000000000003e-08
simulating q_mul_k: Batched_Matmul BS=64 M=1, K=128, N=1025
Batched Matmul: M=1, K=128, N=1025, BS=64
BatchedMatmul latency: 6.081176879882814e-07
q_mul_k latency: 6.081176879882814e-07, compute latency: 6.028048828125e-07, io overhead: 5.31280517578125e-09
simulating a_mul_v: Batched_Matmul BS=64 M=1, K=1025, N=128
Batched Matmul: M=1, K=1025, N=128, BS=64
BatchedMatmul latency: 6.1034150390625e-07
a_mul_v latency: 6.1034150390625e-07, compute latency: 6.078e-07, io overhead: 2.5415039062499997e-09
simulating h_matmul0: Matmul M=1, K=8192, N=8192
h_matmul0 latency: 1.1178000000000001e-06, compute latency: 6.378000000000001e-07, io overhead: 4.8e-07
simulating h1_matmul1: Matmul M=1, K=8192, N=28672
h1_matmul1 latency: 2.2399999999999997e-06, compute latency: 1.36e-06, io overhead: 8.8e-07
simulating h2_matmul2: Matmul M=1, K=28672, N=8192
h2_matmul2 latency: 1.7252e-06, compute latency: 8.851999999999999e-07, io overhead: 8.400000000000001e-07
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 8.779859191894531e-06
matmul total latency: 8.779859191894531e-06
weighted avg simd utilization: 0.10939545351659745
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 0.8915869003572511, 'S': 1.0, 'D': 1.0}
Llama-3.1-70B decode latency per token: 8.779859191894531e-06
Llama-3.1-70B decode total latency for 2048 tokens: 1.43849213
simulated latency: Llama-3.1-70B_decode 1.43849213
Testing LLaMA 3.1 8B model prefill
Simulate Running on DRAM PIM
compute module:
simdram config: 8channels x 32ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 13107.2GB/s
simdram internal bw: 4739326.553672316GB/s
simdram ops: 2368.7223119347013Tops
memory capacity: 1024.0GB
peripheral area: 2113.579418320765mm^2
dram area: 33792.0mm^2

memory module: N/A
io module: N/A
LLM model: Llama-3.1-8B
simulating q_proj: Matmul M=1024, K=4096, N=4096
q_proj latency: 0.0001459648, compute latency: 6.37248e-05, io overhead: 8.224e-05
simulating k_proj: Matmul M=1024, K=4096, N=1024
k_proj latency: 3.7024e-05, compute latency: 1.6224e-05, io overhead: 2.08e-05
simulating v_proj: Matmul M=1024, K=4096, N=1024
skipping v_proj simulation, using k_proj
v_proj latency: 3.7024e-05, compute latency: 1.6224e-05, io overhead: 2.08e-05
simulating q_mul_k: Batched_Matmul BS=32 M=1024, K=128, N=1024
Batched Matmul: M=1024, K=128, N=1024, BS=32
BatchedMatmul latency: 6.9888e-06
q_mul_k latency: 6.9888e-06, compute latency: 4.3488e-06, io overhead: 2.64e-06
simulating a_mul_v: Batched_Matmul BS=32 M=1024, K=1024, N=128
Batched Matmul: M=1024, K=1024, N=128, BS=32
BatchedMatmul latency: 3.0895999999999996e-06
a_mul_v latency: 3.0895999999999996e-06, compute latency: 2.3695999999999997e-06, io overhead: 7.2e-07
simulating h_matmul0: Matmul M=1024, K=4096, N=4096
h_matmul0 latency: 0.0001459648, compute latency: 6.37248e-05, io overhead: 8.224e-05
simulating h1_matmul1: Matmul M=1024, K=4096, N=14336
h1_matmul1 latency: 0.000443392, compute latency: 0.00022323200000000002, io overhead: 0.00022016000000000003
simulating h2_matmul2: Matmul M=1024, K=14336, N=4096
h2_matmul2 latency: 0.0002708096, compute latency: 0.0001274496, io overhead: 0.00014336
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 0.0010902576
matmul total latency: 0.0010902576
weighted avg simd utilization: 0.14731981689464949
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 1.0}
Llama-3.1-8B 32 layers prefill latency: 0.0348882432
simulated latency: Llama-3.1-8B_prefill 0.0348882432
Testing LLaMA 3.1 8B model decode
Simulate Running on DRAM PIM
compute module:
simdram config: 8channels x 32ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 13107.2GB/s
simdram internal bw: 4739326.553672316GB/s
simdram ops: 2368.7223119347013Tops
memory capacity: 1024.0GB
peripheral area: 2113.579418320765mm^2
dram area: 33792.0mm^2

memory module: N/A
io module: N/A
simulating q_proj: Matmul M=1, K=4096, N=4096
q_proj latency: 7.378000000000001e-07, compute latency: 6.378000000000001e-07, io overhead: 1e-07
simulating k_proj: Matmul M=1, K=4096, N=1024
k_proj latency: 6.590500000000001e-07, compute latency: 6.378000000000001e-07, io overhead: 2.1250000000000002e-08
simulating v_proj: Matmul M=1, K=4096, N=1024
skipping v_proj simulation, using k_proj
v_proj latency: 6.590500000000001e-07, compute latency: 6.378000000000001e-07, io overhead: 2.1250000000000002e-08
simulating q_mul_k: Batched_Matmul BS=32 M=1, K=128, N=1025
Batched Matmul: M=1, K=128, N=1025, BS=32
BatchedMatmul latency: 6.081176879882814e-07
q_mul_k latency: 6.081176879882814e-07, compute latency: 6.028048828125e-07, io overhead: 5.31280517578125e-09
simulating a_mul_v: Batched_Matmul BS=32 M=1, K=1025, N=128
Batched Matmul: M=1, K=1025, N=128, BS=32
BatchedMatmul latency: 6.1034150390625e-07
a_mul_v latency: 6.1034150390625e-07, compute latency: 6.078e-07, io overhead: 2.5415039062499997e-09
simulating h_matmul0: Matmul M=1, K=4096, N=4096
h_matmul0 latency: 7.378000000000001e-07, compute latency: 6.378000000000001e-07, io overhead: 1e-07
simulating h1_matmul1: Matmul M=1, K=4096, N=14336
h1_matmul1 latency: 1.1751999999999998e-06, compute latency: 8.751999999999999e-07, io overhead: 3.0000000000000004e-07
simulating h2_matmul2: Matmul M=1, K=14336, N=4096
h2_matmul2 latency: 9.878e-07, compute latency: 6.378000000000001e-07, io overhead: 3.5e-07
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 6.175159191894532e-06
matmul total latency: 6.175159191894532e-06
weighted avg simd utilization: 0.03891083240000671
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 0.8458579414973527, 'S': 1.0, 'D': 1.0}
Llama-3.1-8B decode latency per token: 6.175159191894532e-06
Llama-3.1-8B decode total latency for 2048 tokens: 0.4046952328
simulated latency: Llama-3.1-8B_decode 0.4046952328
