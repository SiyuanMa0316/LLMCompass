Using config: configs/x16{'C': 10, 'R': 64, 'B': 16, 'A': 16, 'S': 1, 'D': 8}16384x1024.json
Running GEMM tests...
Test 1: M=1024, K=12288, N=12288
compute module:
simdram config: 10channels x 64ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 32768.0GB/s
simdram ops: 5921.805779836753Tops
memory capacity: 2560.0GB

memory module: N/A
io module: N/A
Running mapping search...
find_simdram_mapping: Best mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M: CBD  N: A  K: RS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
Running simulation...
--- Input Matmul Size --- M:1024, K:12288, N:12288
Maximum Array Tile Size: {'M': 7, 'K': 192, 'N': 768}
get_arr_tile_stats: arr_latency=0.0001169515, capacity_utilization=0.12451171875
get_tile_stats: K_reduction_latency: 9.325714285714285e-06 = 267386880 / 28672000000000.0
CBD RS ['A'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 0.875}
12582912 = 1024 * 12288 * 1
get_tile_io_latency: data_volume=12582912, dup=['A'], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 0.875}
get_tile_io_latency: latency=7.021714285714286e-06 = 12582912 / 1792000000000.0
get_tile_stats: tile_size: {'M': 1024, 'K': 12288, 'N': 4080}, arr_tile_size: {'M': 1, 'K': 192, 'N': 255}, MK_dup: 1, KN_dup:1, MN_dup:192, M_K_io_latency: 7.021714285714286e-06, K_N_io_latency: 0, M_N_io_latency: 2.7977142857142856e-05, tile_compute_latency:0.00012627721428571428 = 0.0001169515(arr_latency) + 9.325714285714285e-06(K_reduction_latency)
get_arr_tile_stats: arr_latency=2.7199e-06, capacity_utilization=0.00146484375
get_tile_stats: K_reduction_latency: 1.0971428571428572e-07 = 3145728 / 28672000000000.0
CBD RS ['A'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 0.875}
12582912 = 1024 * 12288 * 1
get_tile_io_latency: data_volume=12582912, dup=['A'], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 0.875}
get_tile_io_latency: latency=7.021714285714286e-06 = 12582912 / 1792000000000.0
get_tile_stats: tile_size: {'M': 1024, 'K': 12288, 'N': 48}, arr_tile_size: {'M': 1, 'K': 192, 'N': 3}, MK_dup: 1, KN_dup:1, MN_dup:192, M_K_io_latency: 7.021714285714286e-06, K_N_io_latency: 0, M_N_io_latency: 3.2914285714285717e-07, tile_compute_latency:2.8296142857142855e-06 = 2.7199e-06(arr_latency) + 1.0971428571428572e-07(K_reduction_latency)
================ Strategy Summary ================
Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M: CBD  N: A  K: RS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)

---------------- Tile Sizes ----------------------
| Tile_M      | Tile_N      | Tile_K      |
|-------------|-------------|-------------|
| 1024        | 4080        | 12288       |

| Arr_Tile_M  | Arr_Tile_N  | Arr_Tile_K  |
|-------------|-------------|-------------|
| 1           | 255         | 192         |

--------------- Utilization ----------------------
| Row         | Col         | Array       | Bank        | Device      | Rank        | Channel     |
|-------------|-------------|-------------|-------------|-------------|-------------|-------------|
| 0.12451171875 | 0.1875      | 1           | 1           | 0.875       | 1           | 1           |

------------------ Latency -----------------------
| Total Latency        | 0.0004732726857142857  cycles|
| Total Compute Latency | 0.00038166125714285713 cycles|
| Total Array Latency  | 0.00035357440000000003 cycles|
| Total Reduction Latency| 2.808685714285714e-05  cycles|
| IO Latency           | 9.161142857142856e-05  cycles|

----------- Hardware Requirements ---------------
| col_multicast        | False                 |
| col_broadcast        | False                 |
| broadcast            | {'C': False, 'R': False, 'B': False, 'A': True, 'S': False, 'D': False}|
| reduction            | {'C': False, 'R': True, 'B': False, 'A': False, 'S': True, 'D': False}|
==================================================

---------------- Debug Info -----------------------
| Remaining Tiles       |                         |
|-----------------------|-------------------------|
| M_remain              | 0                      |
| N_remain              | 48                     |
| K_remain              | 0                      |

| Fully Partitioned #Tiles |                       |
|-------------------------|-----------------------|
| M_t                   | 1                      |
| N_t                   | 3                      |
| K_t                   | 1                      |

|------------------------|------------------------|
==================================================
Tiling utilization: {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 0.875}
Column utilization: 0.1875
Capacity utilization: 0.12451171875
GEMM latency: 0.0004732726857142857ms
roofline_model_simdram: total_ops=309237645312, total_data_movement=25165824, peak_flops=5921805779836752.0, bandwidth=32768000000000.0
roofline_model_simdram: compute_bound_time=5.222016000000001e-05, memory_bound_time=7.68e-07
GEMM roofline latency: 5.222016000000001e-05ms
Results written to test_gemm_x16{'C': 10, 'R': 64, 'B': 16, 'A': 16, 'S': 1, 'D': 8}16384x1024.json_1024_12288_12288_simdram_ddr5_operandocality.csv
Test 2: M=2048, K=24576, N=24576
compute module:
simdram config: 10channels x 64ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 32768.0GB/s
simdram ops: 5921.805779836753Tops
memory capacity: 2560.0GB

memory module: N/A
io module: N/A
Running mapping search...
find_simdram_mapping: Best mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M: BAD  N: C  K: RS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
Running simulation...
--- Input Matmul Size --- M:2048, K:24576, N:24576
Maximum Array Tile Size: {'M': 1, 'K': 384, 'N': 2458}
get_arr_tile_stats: arr_latency=0.00046508590000000005, capacity_utilization=0.49951171875
get_tile_stats: K_reduction_latency: 4.092e-05 = 1340866560 / 32768000000000.0
BAD RS ['C'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
50331648 = 2048 * 24576 * 1
get_tile_io_latency: data_volume=503316480, dup=[], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=1.536e-05 = 503316480 / 32768000000000.0
get_tile_stats: tile_size: {'M': 2048, 'K': 24576, 'N': 10230}, arr_tile_size: {'M': 1, 'K': 384, 'N': 1023}, MK_dup: 1, KN_dup:1, MN_dup:384, M_K_io_latency: 1.536e-05, K_N_io_latency: 0, M_N_io_latency: 0.00024552, tile_compute_latency:0.0005060059 = 0.00046508590000000005(arr_latency) + 4.092e-05(K_reduction_latency)
get_arr_tile_stats: arr_latency=0.0001881196, capacity_utilization=0.201171875
get_tile_stats: K_reduction_latency: 1.6464e-05 = 539492352 / 32768000000000.0
BAD RS ['C'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
50331648 = 2048 * 24576 * 1
get_tile_io_latency: data_volume=503316480, dup=[], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=1.536e-05 = 503316480 / 32768000000000.0
get_tile_stats: tile_size: {'M': 2048, 'K': 24576, 'N': 4116}, arr_tile_size: {'M': 1, 'K': 384, 'N': 412}, MK_dup: 1, KN_dup:1, MN_dup:384, M_K_io_latency: 1.536e-05, K_N_io_latency: 0, M_N_io_latency: 9.878400000000001e-05, tile_compute_latency:0.0002045836 = 0.0001881196(arr_latency) + 1.6464e-05(K_reduction_latency)
================ Strategy Summary ================
Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M: BAD  N: C  K: RS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)

---------------- Tile Sizes ----------------------
| Tile_M      | Tile_N      | Tile_K      |
|-------------|-------------|-------------|
| 2048        | 10230       | 24576       |

| Arr_Tile_M  | Arr_Tile_N  | Arr_Tile_K  |
|-------------|-------------|-------------|
| 1           | 1023        | 384         |

--------------- Utilization ----------------------
| Row         | Col         | Array       | Bank        | Device      | Rank        | Channel     |
|-------------|-------------|-------------|-------------|-------------|-------------|-------------|
| 0.49951171875 | 0.375       | 1           | 1           | 1           | 1           | 1           |

------------------ Latency -----------------------
| Total Latency        | 0.0019205633999999998  cycles|
| Total Compute Latency | 0.0012165954           cycles|
| Total Array Latency  | 0.0011182914000000001  cycles|
| Total Reduction Latency| 9.8304e-05             cycles|
| IO Latency           | 0.0007039679999999999  cycles|

----------- Hardware Requirements ---------------
| col_multicast        | False                 |
| col_broadcast        | False                 |
| broadcast            | {'C': True, 'R': False, 'B': False, 'A': False, 'S': False, 'D': False}|
| reduction            | {'C': False, 'R': True, 'B': False, 'A': False, 'S': True, 'D': False}|
==================================================

---------------- Debug Info -----------------------
| Remaining Tiles       |                         |
|-----------------------|-------------------------|
| M_remain              | 0                      |
| N_remain              | 4116                   |
| K_remain              | 0                      |

| Fully Partitioned #Tiles |                       |
|-------------------------|-----------------------|
| M_t                   | 1                      |
| N_t                   | 2                      |
| K_t                   | 1                      |

|------------------------|------------------------|
==================================================
Tiling utilization: {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
Column utilization: 0.375
Capacity utilization: 0.49951171875
GEMM latency: 0.0019205633999999998ms
roofline_model_simdram: total_ops=2473901162496, total_data_movement=100663296, peak_flops=5921805779836752.0, bandwidth=32768000000000.0
roofline_model_simdram: compute_bound_time=0.0004177612800000001, memory_bound_time=3.072e-06
GEMM roofline latency: 0.0004177612800000001ms
Results written to test_gemm_x16{'C': 10, 'R': 64, 'B': 16, 'A': 16, 'S': 1, 'D': 8}16384x1024.json_2048_24576_24576_simdram_ddr5_operandocality.csv
Test 3: M=1, K=12288, N=12288
compute module:
simdram config: 10channels x 64ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 32768.0GB/s
simdram ops: 5921.805779836753Tops
memory capacity: 2560.0GB

memory module: N/A
io module: N/A
Running mapping search...
find_simdram_mapping: Best mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: CRD  K: BAS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
Running simulation...
--- Input Matmul Size --- M:1, K:12288, N:12288
Maximum Array Tile Size: {'M': 1, 'K': 48, 'N': 3}
get_arr_tile_stats: arr_latency=2.7199e-06, capacity_utilization=0.00146484375
get_tile_stats: K_reduction_latency: 9.6e-08 = 3145728 / 32768000000000.0
 BAS ['C', 'R', 'D'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
12288 = 1 * 12288 * 1
get_tile_io_latency: data_volume=62914560, dup=[], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=1.92e-06 = 62914560 / 32768000000000.0
get_tile_stats: tile_size: {'M': 1, 'K': 12288, 'N': 12288}, arr_tile_size: {'M': 1, 'K': 48, 'N': 3}, MK_dup: 1, KN_dup:1, MN_dup:48, M_K_io_latency: 1.92e-06, K_N_io_latency: 0, M_N_io_latency: 1.8e-08, tile_compute_latency:2.8159e-06 = 2.7199e-06(arr_latency) + 9.6e-08(K_reduction_latency)
================ Strategy Summary ================
Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: CRD  K: BAS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)

---------------- Tile Sizes ----------------------
| Tile_M      | Tile_N      | Tile_K      |
|-------------|-------------|-------------|
| 1           | 12288       | 12288       |

| Arr_Tile_M  | Arr_Tile_N  | Arr_Tile_K  |
|-------------|-------------|-------------|
| 1           | 3           | 48          |

--------------- Utilization ----------------------
| Row         | Col         | Array       | Bank        | Device      | Rank        | Channel     |
|-------------|-------------|-------------|-------------|-------------|-------------|-------------|
| 0.00146484375 | 0.046875    | 1           | 1           | 1           | 1           | 1           |

------------------ Latency -----------------------
| Total Latency        | 4.7719e-06             cycles|
| Total Compute Latency | 2.8159e-06             cycles|
| Total Array Latency  | 2.7199e-06             cycles|
| Total Reduction Latency| 9.6e-08                cycles|
| IO Latency           | 1.956e-06              cycles|

----------- Hardware Requirements ---------------
| col_multicast        | False                 |
| col_broadcast        | False                 |
| broadcast            | {'C': True, 'R': True, 'B': False, 'A': False, 'S': False, 'D': True}|
| reduction            | {'C': False, 'R': False, 'B': True, 'A': True, 'S': True, 'D': False}|
==================================================

---------------- Debug Info -----------------------
| Remaining Tiles       |                         |
|-----------------------|-------------------------|
| M_remain              | 0                      |
| N_remain              | 0                      |
| K_remain              | 0                      |

| Fully Partitioned #Tiles |                       |
|-------------------------|-----------------------|
| M_t                   | 1                      |
| N_t                   | 1                      |
| K_t                   | 1                      |

|------------------------|------------------------|
==================================================
Tiling utilization: {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
Column utilization: 0.046875
Capacity utilization: 0.00146484375
GEMM latency: 4.7719e-06ms
roofline_model_simdram: total_ops=301989888, total_data_movement=24576, peak_flops=5921805779836752.0, bandwidth=32768000000000.0
roofline_model_simdram: compute_bound_time=5.099625000000001e-08, memory_bound_time=7.5e-10
GEMM roofline latency: 5.099625000000001e-08ms
Results written to test_gemm_x16{'C': 10, 'R': 64, 'B': 16, 'A': 16, 'S': 1, 'D': 8}16384x1024.json_1_12288_12288_simdram_ddr5_operandocality.csv
Test 4: M=1, K=24576, N=24576
compute module:
simdram config: 10channels x 64ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 32768.0GB/s
simdram ops: 5921.805779836753Tops
memory capacity: 2560.0GB

memory module: N/A
io module: N/A
Running mapping search...
find_simdram_mapping: Best mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: CRD  K: BAS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
Running simulation...
--- Input Matmul Size --- M:1, K:24576, N:24576
Maximum Array Tile Size: {'M': 1, 'K': 96, 'N': 5}
get_arr_tile_stats: arr_latency=3.6265000000000003e-06, capacity_utilization=0.00244140625
get_tile_stats: K_reduction_latency: 1.92e-07 = 6291456 / 32768000000000.0
 BAS ['C', 'R', 'D'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
24576 = 1 * 24576 * 1
get_tile_io_latency: data_volume=125829120, dup=[], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=3.84e-06 = 125829120 / 32768000000000.0
get_tile_stats: tile_size: {'M': 1, 'K': 24576, 'N': 24576}, arr_tile_size: {'M': 1, 'K': 96, 'N': 5}, MK_dup: 1, KN_dup:1, MN_dup:96, M_K_io_latency: 3.84e-06, K_N_io_latency: 0, M_N_io_latency: 7.2e-08, tile_compute_latency:3.8185e-06 = 3.6265000000000003e-06(arr_latency) + 1.92e-07(K_reduction_latency)
================ Strategy Summary ================
Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: CRD  K: BAS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)

---------------- Tile Sizes ----------------------
| Tile_M      | Tile_N      | Tile_K      |
|-------------|-------------|-------------|
| 1           | 24576       | 24576       |

| Arr_Tile_M  | Arr_Tile_N  | Arr_Tile_K  |
|-------------|-------------|-------------|
| 1           | 5           | 96          |

--------------- Utilization ----------------------
| Row         | Col         | Array       | Bank        | Device      | Rank        | Channel     |
|-------------|-------------|-------------|-------------|-------------|-------------|-------------|
| 0.00244140625 | 0.09375     | 1           | 1           | 1           | 1           | 1           |

------------------ Latency -----------------------
| Total Latency        | 7.8025e-06             cycles|
| Total Compute Latency | 3.8185e-06             cycles|
| Total Array Latency  | 3.6265000000000003e-06 cycles|
| Total Reduction Latency| 1.92e-07               cycles|
| IO Latency           | 3.984e-06              cycles|

----------- Hardware Requirements ---------------
| col_multicast        | False                 |
| col_broadcast        | False                 |
| broadcast            | {'C': True, 'R': True, 'B': False, 'A': False, 'S': False, 'D': True}|
| reduction            | {'C': False, 'R': False, 'B': True, 'A': True, 'S': True, 'D': False}|
==================================================

---------------- Debug Info -----------------------
| Remaining Tiles       |                         |
|-----------------------|-------------------------|
| M_remain              | 0                      |
| N_remain              | 0                      |
| K_remain              | 0                      |

| Fully Partitioned #Tiles |                       |
|-------------------------|-----------------------|
| M_t                   | 1                      |
| N_t                   | 1                      |
| K_t                   | 1                      |

|------------------------|------------------------|
==================================================
Tiling utilization: {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
Column utilization: 0.09375
Capacity utilization: 0.00244140625
GEMM latency: 7.8025e-06ms
roofline_model_simdram: total_ops=1207959552, total_data_movement=49152, peak_flops=5921805779836752.0, bandwidth=32768000000000.0
roofline_model_simdram: compute_bound_time=2.0398500000000004e-07, memory_bound_time=1.5e-09
GEMM roofline latency: 2.0398500000000004e-07ms
Results written to test_gemm_x16{'C': 10, 'R': 64, 'B': 16, 'A': 16, 'S': 1, 'D': 8}16384x1024.json_1_24576_24576_simdram_ddr5_operandocality.csv
Running LLM tests...
Testing GPT-3 175B model prefill
Simulate Running on DRAM PIM
compute module:
simdram config: 10channels x 64ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 32768.0GB/s
simdram ops: 5921.805779836753Tops
memory capacity: 2560.0GB

memory module: N/A
io module: N/A
LLM model: gpt3-175B
simulating qkv: 
qkv latency: 0.0014828180571428572, compute latency: 0.00038166125714285713, io overhead: 9.161142857142856e-05
simulating q_mul_k
Batched Matmul: M=1024, K=128, N=1024, BS=96
BatchedMatmul latency: 0.0006194976000000001
q_mul_k latency: 0.0006404976000000001, compute latency: 0.0004597536, io overhead: 0.00015974400000000002
simulating a_mul_v
Batched Matmul: M=1024, K=1024, N=128, BS=96
BatchedMatmul latency: 0.0005054838857142857
a_mul_v latency: 0.0005264838857142857, compute latency: 0.00022461531428571432, io overhead: 0.0002808685714285714
simulating h_matmul0
h_matmul0 latency: 0.0004942726857142857, compute latency: 0.00038166125714285713, io overhead: 9.161142857142856e-05
simulating h1_matmul1
h1_matmul1 latency: 0.001661846, compute latency: 0.0012161420000000001, io overhead: 0.00042470400000000003
simulating h2_matmul2
h2_matmul2 latency: 0.0007691069714285715, compute latency: 0.00038166125714285713, io overhead: 0.00036644571428571425
finish matmul simulation
matmul total overhead: 0.000168
matmul total latency w/o overhead: 0.0054070252
matmul total latency: 0.0055750252
weighted avg simd utilization: 0.23354941708860544
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 0.9266218204717711}
gpt3-175B 96 layers prefill latency: 0.5493144191999999
Testing GPT-3 175B model decode
Simulate Running on DRAM PIM
compute module:
simdram config: 10channels x 64ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 32768.0GB/s
simdram ops: 5921.805779836753Tops
memory capacity: 2560.0GB

memory module: N/A
io module: N/A
simulating qkv: 
qkv mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: CRD  K: BAS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
q_mul_k mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: RBD  K: CAS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
a_mul_v mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: CB  K: RADS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
h_matmul0 mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: CRD  K: BAS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
h1_matmul1 mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: RBD  K: CAS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
h2_matmul2 mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: BAD  K: CRS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
qkv latency: 7.73157e-05, compute latency: 8.4477e-06, io overhead: 5.868e-06, kernel launch overhead: 6.3e-05
simulating q_mul_k
Batched Matmul: M=1, K=128, N=1025, BS=96
BatchedMatmul latency: 0.00017980916538461538
q_mul_k latency: 0.00020080916538461538, compute latency: 0.000175998675, io overhead: 3.8104903846153843e-06, kernel launch overhead: 2.1e-05
simulating a_mul_v
Batched Matmul: M=1, K=1025, N=128, BS=96
BatchedMatmul latency: 0.0001797832903846154
a_mul_v latency: 0.0002007832903846154, compute latency: 0.00017785772307692309, io overhead: 1.925567307692308e-06, kernel launch overhead: 2.1e-05
simulating h_matmul0
h_matmul0 latency: 2.57719e-05, compute latency: 2.8159e-06, io overhead: 1.956e-06, kernel launch overhead: 2.1e-05
simulating h1_matmul1
h1_matmul1 latency: 2.86228e-05, compute latency: 4.3198000000000006e-06, io overhead: 3.303e-06, kernel launch overhead: 2.1e-05
simulating h2_matmul2
h2_matmul2 latency: 2.844955e-05, compute latency: 4.3198000000000006e-06, io overhead: 3.12975e-06, kernel launch overhead: 2.1e-05
finish matmul simulation
matmul total overhead: 0.000168
matmul total latency w/o overhead: 0.00039375240576923086
matmul total latency: 0.0005617524057692308
weighted avg simd utilization: 0.01693981988900587
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 0.9329831673874827, 'A': 0.9329745309091156, 'S': 1.0, 'D': 0.4638307931863946}
gpt3-175B decode latency per token: 0.0007087524057692308
gpt3-175B decode total latency for 2048 tokens: 1.5188564055634617
Testing GPT-3 6.7B model prefill
Simulate Running on DRAM PIM
compute module:
simdram config: 10channels x 64ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 32768.0GB/s
simdram ops: 5921.805779836753Tops
memory capacity: 2560.0GB

memory module: N/A
io module: N/A
LLM model: gpt3-6.7B
simulating qkv: 
qkv latency: 0.00037126680000000003, compute latency: 2.6979600000000005e-05, io overhead: 7.5776e-05
simulating q_mul_k
Batched Matmul: M=1024, K=128, N=1024, BS=32
BatchedMatmul latency: 0.00020649920000000003
q_mul_k latency: 0.00022749920000000003, compute latency: 0.00015325120000000001, io overhead: 5.3248e-05
simulating a_mul_v
Batched Matmul: M=1024, K=1024, N=128, BS=32
BatchedMatmul latency: 0.00016849462857142857
a_mul_v latency: 0.00018949462857142856, compute latency: 7.487177142857144e-05, io overhead: 9.362285714285713e-05
simulating h_matmul0
h_matmul0 latency: 0.0001237556, compute latency: 2.6979600000000005e-05, io overhead: 7.5776e-05
simulating h1_matmul1
h1_matmul1 latency: 0.0003088710857142857, compute latency: 0.0001281270857142857, io overhead: 0.000159744
simulating h2_matmul2
h2_matmul2 latency: 0.0001960848, compute latency: 0.0001281270857142857, io overhead: 4.695771428571429e-05
finish matmul simulation
matmul total overhead: 0.000168
matmul total latency w/o overhead: 0.0012489721142857145
matmul total latency: 0.0014169721142857144
weighted avg simd utilization: 0.18729561297546654
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 0.9387381632916094}
gpt3-6.7B 32 layers prefill latency: 0.05004710765714286
Testing GPT-3 6.7B model decode
Simulate Running on DRAM PIM
compute module:
simdram config: 10channels x 64ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 32768.0GB/s
simdram ops: 5921.805779836753Tops
memory capacity: 2560.0GB

memory module: N/A
io module: N/A
simulating qkv: 
qkv mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: CRD  K: BAS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
q_mul_k mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: RBD  K: CAS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
a_mul_v mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: CB  K: RADS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
h_matmul0 mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: CRD  K: BAS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
h1_matmul1 mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: RBD  K: CAS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
h2_matmul2 mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: False
  Tile Mapping:  M:   N: BAD  K: CRS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
qkv latency: 7.048332857142857e-05, compute latency: 5.549614285714286e-06, io overhead: 1.9337142857142858e-06, kernel launch overhead: 6.3e-05
simulating q_mul_k
Batched Matmul: M=1, K=128, N=1025, BS=32
BatchedMatmul latency: 5.993638846153846e-05
q_mul_k latency: 8.093638846153846e-05, compute latency: 5.8666225e-05, io overhead: 1.2701634615384614e-06, kernel launch overhead: 2.1e-05
simulating a_mul_v
Batched Matmul: M=1, K=1025, N=128, BS=32
BatchedMatmul latency: 5.9927763461538466e-05
a_mul_v latency: 8.092776346153846e-05, compute latency: 5.9285907692307695e-05, io overhead: 6.418557692307693e-07, kernel launch overhead: 2.1e-05
simulating h_matmul0
h_matmul0 latency: 2.3494442857142856e-05, compute latency: 1.8498714285714287e-06, io overhead: 6.445714285714286e-07, kernel launch overhead: 2.1e-05
simulating h1_matmul1
h1_matmul1 latency: 2.43966e-05, compute latency: 2.3466e-06, io overhead: 1.05e-06, kernel launch overhead: 2.1e-05
simulating h2_matmul2
h2_matmul2 latency: 2.43771e-05, compute latency: 2.3466e-06, io overhead: 1.0305e-06, kernel launch overhead: 2.1e-05
finish matmul simulation
matmul total overhead: 0.000168
matmul total latency w/o overhead: 0.00013661562335164835
matmul total latency: 0.00030461562335164834
weighted avg simd utilization: 0.00940486188618469
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 0.950186548273259, 'A': 0.950181239328556, 'S': 1.0, 'D': 0.5629070698807325}
gpt3-6.7B decode latency per token: 0.00045161562335164834
gpt3-6.7B decode total latency for 2048 tokens: 0.9389088809480769
Testing LLaMA 3.1 70B model prefill
Simulate Running on DRAM PIM
compute module:
simdram config: 10channels x 64ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 32768.0GB/s
simdram ops: 5921.805779836753Tops
memory capacity: 2560.0GB

memory module: N/A
io module: N/A
LLM model: Llama-3.1-70B
simulating q_proj: Matmul M=1024, K=8192, N=8192
q_proj latency: 0.00031151960000000005, compute latency: 0.00020450360000000002, io overhead: 8.601600000000001e-05
simulating k_proj: Matmul M=1024, K=8192, N=1024
k_proj latency: 6.46192e-05, compute latency: 3.29312e-05, io overhead: 1.0688e-05
simulating v_proj: Matmul M=1024, K=8192, N=1024
skipping v_proj simulation, using k_proj
v_proj latency: 6.46192e-05, compute latency: 3.29312e-05, io overhead: 1.0688e-05
simulating q_mul_k: Batched_Matmul BS=64 M=1024, K=128, N=1024
Batched Matmul: M=1024, K=128, N=1024, BS=64
BatchedMatmul latency: 0.00041299840000000006
q_mul_k latency: 0.0004339984000000001, compute latency: 0.00030650240000000003, io overhead: 0.000106496
simulating a_mul_v: Batched_Matmul BS=64 M=1024, K=1024, N=128
Batched Matmul: M=1024, K=1024, N=128, BS=64
BatchedMatmul latency: 0.00033698925714285713
a_mul_v latency: 0.00035798925714285716, compute latency: 0.00014974354285714287, io overhead: 0.00018724571428571426
simulating h_matmul0: Matmul M=1024, K=8192, N=8192
h_matmul0 latency: 0.00031151960000000005, compute latency: 0.00020450360000000002, io overhead: 8.601600000000001e-05
simulating h1_matmul1: Matmul M=1024, K=8192, N=28672
h1_matmul1 latency: 0.0009804987999999998, compute latency: 0.0007096428, io overhead: 0.000249856
simulating h2_matmul2: Matmul M=1024, K=28672, N=8192
h2_matmul2 latency: 0.0004238621714285715, compute latency: 0.0002548941714285714, io overhead: 0.000147968
finish matmul simulation
matmul total overhead: 0.000168
matmul total latency w/o overhead: 0.0027806262285714283
matmul total latency: 0.0029486262285714285
weighted avg simd utilization: 0.14172054563726524
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 0.9694161745680335}
Llama-3.1-70B 80 layers prefill latency: 0.24765009828571427
Testing LLaMA 3.1 70B model decode
Simulate Running on DRAM PIM
compute module:
simdram config: 10channels x 64ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 32768.0GB/s
simdram ops: 5921.805779836753Tops
memory capacity: 2560.0GB

memory module: N/A
io module: N/A
simulating q_proj: Matmul M=1, K=8192, N=8192
q_proj latency: 2.46266e-05, compute latency: 2.3306e-06, io overhead: 1.296e-06
simulating k_proj: Matmul M=1, K=8192, N=1024
k_proj latency: 2.31097375e-05, compute latency: 1.8533000000000001e-06, io overhead: 2.564375e-07
simulating v_proj: Matmul M=1, K=8192, N=1024
skipping v_proj simulation, using k_proj
v_proj latency: 2.31097375e-05, compute latency: 1.8533000000000001e-06, io overhead: 2.564375e-07
simulating q_mul_k: Batched_Matmul BS=64 M=1, K=128, N=1025
Batched Matmul: M=1, K=128, N=1025, BS=64
BatchedMatmul latency: 0.00011987277692307692
q_mul_k latency: 0.00014087277692307693, compute latency: 0.00011733245, io overhead: 2.540326923076923e-06
simulating a_mul_v: Batched_Matmul BS=64 M=1, K=1025, N=128
Batched Matmul: M=1, K=1025, N=128, BS=64
BatchedMatmul latency: 0.00011985552692307693
a_mul_v latency: 0.00014085552692307693, compute latency: 0.00011857181538461539, io overhead: 1.2837115384615385e-06
simulating h_matmul0: Matmul M=1, K=8192, N=8192
h_matmul0 latency: 2.46266e-05, compute latency: 2.3306e-06, io overhead: 1.296e-06
simulating h1_matmul1: Matmul M=1, K=8192, N=28672
h1_matmul1 latency: 2.6452199999999997e-05, compute latency: 3.3132000000000003e-06, io overhead: 2.1389999999999998e-06
simulating h2_matmul2: Matmul M=1, K=28672, N=8192
h2_matmul2 latency: 2.61477e-05, compute latency: 3.3332000000000005e-06, io overhead: 1.8145000000000002e-06
finish matmul simulation
matmul total overhead: 0.000168
matmul total latency w/o overhead: 0.0002618008788461539
matmul total latency: 0.0004298008788461539
weighted avg simd utilization: 0.010741396889449396
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 0.9387680849490463, 'A': 0.9387605861269716, 'S': 1.0, 'D': 0.5101146843040715}
Llama-3.1-70B decode latency per token: 0.0005768008788461539
Llama-3.1-70B decode total latency for 2048 tokens: 1.2268554693057692
Testing LLaMA 3.1 8B model prefill
Simulate Running on DRAM PIM
compute module:
simdram config: 10channels x 64ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 32768.0GB/s
simdram ops: 5921.805779836753Tops
memory capacity: 2560.0GB

memory module: N/A
io module: N/A
LLM model: Llama-3.1-8B
simulating q_proj: Matmul M=1024, K=4096, N=4096
q_proj latency: 0.0001237556, compute latency: 2.6979600000000005e-05, io overhead: 7.5776e-05
simulating k_proj: Matmul M=1024, K=4096, N=1024
k_proj latency: 5.53889e-05, compute latency: 7.7649e-06, io overhead: 2.6624e-05
simulating v_proj: Matmul M=1024, K=4096, N=1024
skipping v_proj simulation, using k_proj
v_proj latency: 5.53889e-05, compute latency: 7.7649e-06, io overhead: 2.6624e-05
simulating q_mul_k: Batched_Matmul BS=32 M=1024, K=128, N=1024
Batched Matmul: M=1024, K=128, N=1024, BS=32
BatchedMatmul latency: 0.00020649920000000003
q_mul_k latency: 0.00022749920000000003, compute latency: 0.00015325120000000001, io overhead: 5.3248e-05
simulating a_mul_v: Batched_Matmul BS=32 M=1024, K=1024, N=128
Batched Matmul: M=1024, K=1024, N=128, BS=32
BatchedMatmul latency: 0.00016849462857142857
a_mul_v latency: 0.00018949462857142856, compute latency: 7.487177142857144e-05, io overhead: 9.362285714285713e-05
simulating h_matmul0: Matmul M=1024, K=4096, N=4096
h_matmul0 latency: 0.0001237556, compute latency: 2.6979600000000005e-05, io overhead: 7.5776e-05
simulating h1_matmul1: Matmul M=1024, K=4096, N=14336
h1_matmul1 latency: 0.000350738, compute latency: 9.0122e-05, io overhead: 0.000239616
simulating h2_matmul2: Matmul M=1024, K=14336, N=4096
h2_matmul2 latency: 0.00019021508571428572, compute latency: 0.0001281270857142857, io overhead: 4.1088000000000004e-05
finish matmul simulation
matmul total overhead: 0.000168
matmul total latency w/o overhead: 0.0011482359142857145
matmul total latency: 0.0013162359142857144
weighted avg simd utilization: 0.18153660963249246
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 0.9657203346317528}
Llama-3.1-8B 32 layers prefill latency: 0.04682354925714286
Testing LLaMA 3.1 8B model decode
Simulate Running on DRAM PIM
compute module:
simdram config: 10channels x 64ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 32768.0GB/s
simdram ops: 5921.805779836753Tops
memory capacity: 2560.0GB

memory module: N/A
io module: N/A
simulating q_proj: Matmul M=1, K=4096, N=4096
q_proj latency: 2.3494442857142856e-05, compute latency: 1.8498714285714287e-06, io overhead: 6.445714285714286e-07
simulating k_proj: Matmul M=1, K=4096, N=1024
k_proj latency: 2.298155e-05, compute latency: 1.8533000000000001e-06, io overhead: 1.2825000000000003e-07
simulating v_proj: Matmul M=1, K=4096, N=1024
skipping v_proj simulation, using k_proj
v_proj latency: 2.298155e-05, compute latency: 1.8533000000000001e-06, io overhead: 1.2825000000000003e-07
simulating q_mul_k: Batched_Matmul BS=32 M=1, K=128, N=1025
Batched Matmul: M=1, K=128, N=1025, BS=32
BatchedMatmul latency: 5.993638846153846e-05
q_mul_k latency: 8.093638846153846e-05, compute latency: 5.8666225e-05, io overhead: 1.2701634615384614e-06
simulating a_mul_v: Batched_Matmul BS=32 M=1, K=1025, N=128
Batched Matmul: M=1, K=1025, N=128, BS=32
BatchedMatmul latency: 5.9927763461538466e-05
a_mul_v latency: 8.092776346153846e-05, compute latency: 5.9285907692307695e-05, io overhead: 6.418557692307693e-07
simulating h_matmul0: Matmul M=1, K=4096, N=4096
h_matmul0 latency: 2.3494442857142856e-05, compute latency: 1.8498714285714287e-06, io overhead: 6.445714285714286e-07
simulating h1_matmul1: Matmul M=1, K=4096, N=14336
h1_matmul1 latency: 2.4383349999999998e-05, compute latency: 2.3366e-06, io overhead: 1.04675e-06
simulating h2_matmul2: Matmul M=1, K=14336, N=4096
h2_matmul2 latency: 2.424835e-05, compute latency: 2.3466e-06, io overhead: 9.017499999999999e-07
finish matmul simulation
matmul total overhead: 0.000168
matmul total latency w/o overhead: 0.00013544783763736268
matmul total latency: 0.00030344783763736267
weighted avg simd utilization: 0.007361371363754601
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 0.9500792236406577, 'A': 0.9500739032576682, 'S': 1.0, 'D': 0.5812889235739811}
Llama-3.1-8B decode latency per token: 0.00045044783763736266
Llama-3.1-8B decode total latency for 2048 tokens: 0.9364810544480769
