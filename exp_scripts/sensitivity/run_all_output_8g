Using config: configs/x16_8g.json
Running GEMM tests...
Test 1: M=1024, K=12288, N=12288
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram logical config: 1channels x 2ranks x 16banks x 8arrays x 1subarrays x 131072subarr_rows x 256cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 5.3718032786885255Tops
memory capacity: 8.0GB
peripheral area: 6.489116373236071mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
Running mapping search...
find_simdram_mapping: Best mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: True
  Tile Mapping:  M: RB  N: A  K: DCS  Array Mapping:  R: K  C: MN
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
Running simulation...
--- Input Matmul Size --- M:1024, K:12288, N:12288
Maximum Array Tile Size: {'M': 32, 'K': 1536, 'N': 1536}
get_arr_tile_stats: arr_latency=0.000196992, capacity_utilization=0.1875
get_tile_stats: K_reduction_latency: 5.12e-06 = 524288 / 102400000000.0
RB DCS ['A'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
6291456 = 512 * 12288 * 1
get_tile_io_latency: data_volume=6291456, dup=['A'], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=6.144e-05 = 6291456 / 102400000000.0
get_tile_stats: tile_size: {'M': 512, 'K': 12288, 'N': 128}, arr_tile_size: {'M': 16, 'K': 1536, 'N': 16}, MK_dup: 16, KN_dup:16, MN_dup:1, M_K_io_latency: 0.00098304, K_N_io_latency: 0, M_N_io_latency: 6.4e-07, tile_compute_latency:0.000202112 = 0.000196992(arr_latency) + 5.12e-06(K_reduction_latency)
================ Strategy Summary ================
Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: True
  Tile Mapping:  M: RB  N: A  K: DCS  Array Mapping:  R: K  C: MN
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)

---------------- Tile Sizes ----------------------
| Tile_M      | Tile_N      | Tile_K      |
|-------------|-------------|-------------|
| 512         | 128         | 12288       |

| Arr_Tile_M  | Arr_Tile_N  | Arr_Tile_K  |
|-------------|-------------|-------------|
| 16          | 16          | 1536        |

--------------- Utilization ----------------------
| Row         | Col         | Array       | Bank        | Device      | Rank        | Channel     |
|-------------|-------------|-------------|-------------|-------------|-------------|-------------|
| 0.1875      | 1.0         | 1           | 1           | 1           | 1           | 1           |

------------------ Latency -----------------------
| Total Latency        | 0.04089510400000007    cycles|
| Total Compute Latency | 0.03880550399999999    cycles|
| Total Array Latency  | 0.037822464            cycles|
| Total Reduction Latency| 0.0009830399999999958  cycles|
| IO Latency           | 0.0020896000000000196  cycles|

----------- Hardware Requirements ---------------
| col_multicast        | True                  |
| col_broadcast        | False                 |
| broadcast            | {'C': False, 'R': False, 'B': False, 'A': True, 'S': False, 'D': False}|
| reduction            | {'C': True, 'R': False, 'B': False, 'A': False, 'S': True, 'D': True}|
==================================================

---------------- Debug Info -----------------------
| Remaining Tiles       |                         |
|-----------------------|-------------------------|
| M_remain              | 0                      |
| N_remain              | 0                      |
| K_remain              | 0                      |

| Fully Partitioned #Tiles |                       |
|-------------------------|-----------------------|
| M_t                   | 2                      |
| N_t                   | 96                     |
| K_t                   | 1                      |

|------------------------|------------------------|
==================================================
Tiling utilization: {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
Column utilization: 1.0
Capacity utilization: 0.1875
GEMM 1024x12288x12288 latency: 0.04089510400000007s
simulated latency: GEMM_1024x12288x12288 0.04089510400000007
roofline_model_simdram: total_ops=309237645312, total_data_movement=25165824, peak_flops=5371803278688.525, bandwidth=102400000000.0
roofline_model_simdram: compute_bound_time=0.05756682239999999, memory_bound_time=0.00024576
GEMM roofline latency: 0.05756682239999999ms
Results written to test_gemm_x16_8g.json_1024_12288_12288_simdram_ddr5_operandocality.csv
Test 2: M=2048, K=24576, N=24576
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram logical config: 1channels x 2ranks x 16banks x 8arrays x 1subarrays x 131072subarr_rows x 256cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 5.3718032786885255Tops
memory capacity: 8.0GB
peripheral area: 6.489116373236071mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
Running mapping search...
find_simdram_mapping: Best mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: True
  Tile Mapping:  M: BD  N: A  K: RCS  Array Mapping:  R: K  C: MN
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
Running simulation...
--- Input Matmul Size --- M:2048, K:24576, N:24576
Maximum Array Tile Size: {'M': 16, 'K': 12288, 'N': 3072}
get_arr_tile_stats: arr_latency=0.001048832, capacity_utilization=0.9998779296875
get_tile_stats: K_reduction_latency: 5.12e-06 = 524288 / 102400000000.0
BD RCS ['A'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
33550336 = 2048 * 16382 * 1
get_tile_io_latency: data_volume=33550336, dup=['A'], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=0.00032764 = 33550336 / 102400000000.0
get_tile_stats: tile_size: {'M': 2048, 'K': 16382, 'N': 128}, arr_tile_size: {'M': 16, 'K': 8191, 'N': 16}, MK_dup: 16, KN_dup:16, MN_dup:1, M_K_io_latency: 0.00524224, K_N_io_latency: 0, M_N_io_latency: 2.56e-06, tile_compute_latency:0.001053952 = 0.001048832(arr_latency) + 5.12e-06(K_reduction_latency)
get_arr_tile_stats: arr_latency=0.0005248000000000001, capacity_utilization=0.5001220703125
get_tile_stats: K_reduction_latency: 5.12e-06 = 524288 / 102400000000.0
BD RCS ['A'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
16781312 = 2048 * 8194 * 1
get_tile_io_latency: data_volume=16781312, dup=['A'], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=0.00016388 = 16781312 / 102400000000.0
get_tile_stats: tile_size: {'M': 2048, 'K': 8194, 'N': 128}, arr_tile_size: {'M': 16, 'K': 4097, 'N': 16}, MK_dup: 16, KN_dup:16, MN_dup:1, M_K_io_latency: 0.00262208, K_N_io_latency: 0, M_N_io_latency: 2.56e-06, tile_compute_latency:0.00052992 = 0.0005248000000000001(arr_latency) + 5.12e-06(K_reduction_latency)
================ Strategy Summary ================
Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: True
  Tile Mapping:  M: BD  N: A  K: RCS  Array Mapping:  R: K  C: MN
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)

---------------- Tile Sizes ----------------------
| Tile_M      | Tile_N      | Tile_K      |
|-------------|-------------|-------------|
| 2048        | 128         | 16382       |

| Arr_Tile_M  | Arr_Tile_N  | Arr_Tile_K  |
|-------------|-------------|-------------|
| 16          | 16          | 8191        |

--------------- Utilization ----------------------
| Row         | Col         | Array       | Bank        | Device      | Rank        | Channel     |
|-------------|-------------|-------------|-------------|-------------|-------------|-------------|
| 0.9998779296875 | 1.0         | 1           | 1           | 1           | 1           | 1           |

------------------ Latency -----------------------
| Total Latency        | 0.313444863999998      cycles|
| Total Compute Latency | 0.3041034240000003     cycles|
| Total Array Latency  | 0.3021373439999984     cycles|
| Total Reduction Latency| 0.0019660799999999864  cycles|
| IO Latency           | 0.009341440000000235   cycles|

----------- Hardware Requirements ---------------
| col_multicast        | True                  |
| col_broadcast        | False                 |
| broadcast            | {'C': False, 'R': False, 'B': False, 'A': True, 'S': False, 'D': False}|
| reduction            | {'C': True, 'R': True, 'B': False, 'A': False, 'S': True, 'D': False}|
==================================================

---------------- Debug Info -----------------------
| Remaining Tiles       |                         |
|-----------------------|-------------------------|
| M_remain              | 0                      |
| N_remain              | 0                      |
| K_remain              | 8194                   |

| Fully Partitioned #Tiles |                       |
|-------------------------|-----------------------|
| M_t                   | 1                      |
| N_t                   | 192                    |
| K_t                   | 1                      |

|------------------------|------------------------|
==================================================
Tiling utilization: {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
Column utilization: 1.0
Capacity utilization: 0.9998779296875
GEMM 2048x24576x24576 latency: 0.313444863999998s
simulated latency: GEMM_2048x24576x24576 0.313444863999998
roofline_model_simdram: total_ops=2473901162496, total_data_movement=100663296, peak_flops=5371803278688.525, bandwidth=102400000000.0
roofline_model_simdram: compute_bound_time=0.4605345791999999, memory_bound_time=0.00098304
GEMM roofline latency: 0.4605345791999999ms
Results written to test_gemm_x16_8g.json_2048_24576_24576_simdram_ddr5_operandocality.csv
Test 3: M=1, K=12288, N=12288
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram logical config: 1channels x 2ranks x 16banks x 8arrays x 1subarrays x 131072subarr_rows x 256cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 5.3718032786885255Tops
memory capacity: 8.0GB
peripheral area: 6.489116373236071mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
Running mapping search...
find_simdram_mapping: Best mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: True
  Tile Mapping:  M:   N: RAD  K: BCS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
Running simulation...
--- Input Matmul Size --- M:1, K:12288, N:12288
Maximum Array Tile Size: {'M': 1, 'K': 768, 'N': 96}
get_arr_tile_stats: arr_latency=1.3312e-05, capacity_utilization=0.005859375
get_tile_stats: K_reduction_latency: 1.92e-06 = 196608 / 102400000000.0
 BCS ['R', 'A', 'D'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
4096 = 1 * 4096 * 1
get_tile_io_latency: data_volume=65536, dup=['A'], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=6.4e-07 = 65536 / 102400000000.0
get_tile_stats: tile_size: {'M': 1, 'K': 4096, 'N': 12288}, arr_tile_size: {'M': 1, 'K': 256, 'N': 96}, MK_dup: 1, KN_dup:1, MN_dup:256, M_K_io_latency: 6.4e-07, K_N_io_latency: 0, M_N_io_latency: 1.2e-07, tile_compute_latency:1.5232000000000001e-05 = 1.3312e-05(arr_latency) + 1.92e-06(K_reduction_latency)
================ Strategy Summary ================
Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: True
  Tile Mapping:  M:   N: RAD  K: BCS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)

---------------- Tile Sizes ----------------------
| Tile_M      | Tile_N      | Tile_K      |
|-------------|-------------|-------------|
| 1           | 12288       | 4096        |

| Arr_Tile_M  | Arr_Tile_N  | Arr_Tile_K  |
|-------------|-------------|-------------|
| 1           | 96          | 256         |

--------------- Utilization ----------------------
| Row         | Col         | Array       | Bank        | Device      | Rank        | Channel     |
|-------------|-------------|-------------|-------------|-------------|-------------|-------------|
| 0.005859375 | 1.0         | 1           | 1           | 1           | 1           | 1           |

------------------ Latency -----------------------
| Total Latency        | 4.7856e-05             cycles|
| Total Compute Latency | 4.5696000000000004e-05 cycles|
| Total Array Latency  | 3.9936000000000005e-05 cycles|
| Total Reduction Latency| 5.759999999999999e-06  cycles|
| IO Latency           | 2.16e-06               cycles|

----------- Hardware Requirements ---------------
| col_multicast        | False                 |
| col_broadcast        | False                 |
| broadcast            | {'C': False, 'R': True, 'B': False, 'A': True, 'S': False, 'D': True}|
| reduction            | {'C': True, 'R': False, 'B': True, 'A': False, 'S': True, 'D': False}|
==================================================

---------------- Debug Info -----------------------
| Remaining Tiles       |                         |
|-----------------------|-------------------------|
| M_remain              | 0                      |
| N_remain              | 0                      |
| K_remain              | 0                      |

| Fully Partitioned #Tiles |                       |
|-------------------------|-----------------------|
| M_t                   | 1                      |
| N_t                   | 1                      |
| K_t                   | 3                      |

|------------------------|------------------------|
==================================================
Tiling utilization: {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
Column utilization: 1.0
Capacity utilization: 0.005859375
GEMM 1x12288x12288 latency: 4.7856e-05s
simulated latency: GEMM_1x12288x12288 4.7856e-05
roofline_model_simdram: total_ops=301989888, total_data_movement=24576, peak_flops=5371803278688.525, bandwidth=102400000000.0
roofline_model_simdram: compute_bound_time=5.621759999999999e-05, memory_bound_time=2.4e-07
GEMM roofline latency: 5.621759999999999e-05ms
Results written to test_gemm_x16_8g.json_1_12288_12288_simdram_ddr5_operandocality.csv
Test 4: M=1, K=24576, N=24576
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram logical config: 1channels x 2ranks x 16banks x 8arrays x 1subarrays x 131072subarr_rows x 256cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 5.3718032786885255Tops
memory capacity: 8.0GB
peripheral area: 6.489116373236071mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
Running mapping search...
find_simdram_mapping: Best mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: True
  Tile Mapping:  M:   N: AD  K: RBCS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
Running simulation...
--- Input Matmul Size --- M:1, K:24576, N:24576
Maximum Array Tile Size: {'M': 1, 'K': 768, 'N': 384}
get_arr_tile_stats: arr_latency=5.248e-05, capacity_utilization=0.0234375
get_tile_stats: K_reduction_latency: 7.68e-06 = 786432 / 102400000000.0
 RBCS ['A', 'D'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
8192 = 1 * 8192 * 1
get_tile_io_latency: data_volume=65536, dup=['A'], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=6.4e-07 = 65536 / 102400000000.0
get_tile_stats: tile_size: {'M': 1, 'K': 8192, 'N': 24576}, arr_tile_size: {'M': 1, 'K': 256, 'N': 384}, MK_dup: 1, KN_dup:1, MN_dup:256, M_K_io_latency: 6.4e-07, K_N_io_latency: 0, M_N_io_latency: 2.4e-07, tile_compute_latency:6.016e-05 = 5.248e-05(arr_latency) + 7.68e-06(K_reduction_latency)
================ Strategy Summary ================
Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: True
  Tile Mapping:  M:   N: AD  K: RBCS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)

---------------- Tile Sizes ----------------------
| Tile_M      | Tile_N      | Tile_K      |
|-------------|-------------|-------------|
| 1           | 24576       | 8192        |

| Arr_Tile_M  | Arr_Tile_N  | Arr_Tile_K  |
|-------------|-------------|-------------|
| 1           | 384         | 256         |

--------------- Utilization ----------------------
| Row         | Col         | Array       | Bank        | Device      | Rank        | Channel     |
|-------------|-------------|-------------|-------------|-------------|-------------|-------------|
| 0.0234375   | 1.0         | 1           | 1           | 1           | 1           | 1           |

------------------ Latency -----------------------
| Total Latency        | 0.00018288             cycles|
| Total Compute Latency | 0.00018048             cycles|
| Total Array Latency  | 0.00015744             cycles|
| Total Reduction Latency| 2.3039999999999996e-05 cycles|
| IO Latency           | 2.4e-06                cycles|

----------- Hardware Requirements ---------------
| col_multicast        | False                 |
| col_broadcast        | False                 |
| broadcast            | {'C': False, 'R': False, 'B': False, 'A': True, 'S': False, 'D': True}|
| reduction            | {'C': True, 'R': True, 'B': True, 'A': False, 'S': True, 'D': False}|
==================================================

---------------- Debug Info -----------------------
| Remaining Tiles       |                         |
|-----------------------|-------------------------|
| M_remain              | 0                      |
| N_remain              | 0                      |
| K_remain              | 0                      |

| Fully Partitioned #Tiles |                       |
|-------------------------|-----------------------|
| M_t                   | 1                      |
| N_t                   | 1                      |
| K_t                   | 3                      |

|------------------------|------------------------|
==================================================
Tiling utilization: {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
Column utilization: 1.0
Capacity utilization: 0.0234375
GEMM 1x24576x24576 latency: 0.00018288s
simulated latency: GEMM_1x24576x24576 0.00018288
roofline_model_simdram: total_ops=1207959552, total_data_movement=49152, peak_flops=5371803278688.525, bandwidth=102400000000.0
roofline_model_simdram: compute_bound_time=0.00022487039999999995, memory_bound_time=4.8e-07
GEMM roofline latency: 0.00022487039999999995ms
Results written to test_gemm_x16_8g.json_1_24576_24576_simdram_ddr5_operandocality.csv
Running LLM tests...
Testing GPT-3 175B model prefill
Simulate Running on DRAM PIM
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram logical config: 1channels x 2ranks x 16banks x 8arrays x 1subarrays x 131072subarr_rows x 256cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 5.3718032786885255Tops
memory capacity: 8.0GB
peripheral area: 6.489116373236071mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
LLM model: gpt3-175B
simulating qkv: Matmul M=1024, K=12288, N=12288
qkv latency: 0.12268531200000021, compute latency: 0.03880550399999999, io overhead: 0.0020896000000000196
simulating q_mul_k: Batched Matmul BS=96 M=1024, K=128, N=1024
Batched Matmul: M=1024, K=128, N=1024, BS=96
BatchedMatmul latency: 9.1904e-05
q_mul_k latency: 9.1904e-05, compute latency: 7.014400000000001e-05, io overhead: 2.1760000000000002e-05
simulating a_mul_v: Batched Matmul BS=96 M=1024, K=1024, N=128
Batched Matmul: M=1024, K=1024, N=128, BS=96
BatchedMatmul latency: 5.3248e-05
a_mul_v latency: 5.3248e-05, compute latency: 4.0447999999999996e-05, io overhead: 1.28e-05
simulating h_matmul0: Matmul M=1024, K=12288, N=12288
h_matmul0 latency: 0.04089510400000007, compute latency: 0.03880550399999999, io overhead: 0.0020896000000000196
simulating h1_matmul1: Matmul M=1024, K=12288, N=49152
h1_matmul1 latency: 0.1564779520000006, compute latency: 0.15205171199999923, io overhead: 0.004426240000000079
simulating h2_matmul2: Matmul M=1024, K=49152, N=12288
h2_matmul2 latency: 0.16003955199999986, compute latency: 0.15205171199999923, io overhead: 0.007987839999999935
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 0.4802430720000007
matmul total latency: 0.4802430720000007
weighted avg simd utilization: 1.0
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 1.0}
gpt3-175B 96 layers prefill latency: 46.103334912000065
simulated latency: gpt3-175B_prefill 46.103334912000065
Testing GPT-3 175B model decode
Simulate Running on DRAM PIM
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram logical config: 1channels x 2ranks x 16banks x 8arrays x 1subarrays x 131072subarr_rows x 256cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 5.3718032786885255Tops
memory capacity: 8.0GB
peripheral area: 6.489116373236071mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
simulating qkv: Matmul M=1, K=12288, N=12288
qkv latency: 0.000143568, compute latency: 0.000137088, io overhead: 6.480000000000001e-06, kernel launch overhead: 0
simulating q_mul_k:BatchedMatmul BS=96 M=1, K=128, N=1025
Batched Matmul: M=1, K=128, N=1025, BS=96
BatchedMatmul latency: 7.280390625e-07
q_mul_k latency: 7.280390625e-07, compute latency: 5.480195312500001e-07, io overhead: 1.8001953125000001e-07, kernel launch overhead: 0
simulating a_mul_v: BatchedMatmul BS=96 M=1, K=1025, N=128
Batched Matmul: M=1, K=1025, N=128, BS=96
BatchedMatmul latency: 5.7465625e-07
a_mul_v latency: 5.7465625e-07, compute latency: 4.1200000000000004e-07, io overhead: 1.6265624999999998e-07, kernel launch overhead: 0
simulating h_matmul0: Matmul M=1, K=12288, N=12288
h_matmul0 latency: 4.7856e-05, compute latency: 4.5696000000000004e-05, io overhead: 2.16e-06, kernel launch overhead: 0
simulating h1_matmul1: Matmul M=1, K=12288, N=49152
h1_matmul1 latency: 0.00018335999999999998, compute latency: 0.00018048, io overhead: 2.88e-06, kernel launch overhead: 0
simulating h2_matmul2: Matmul M=1, K=49152, N=12288
h2_matmul2 latency: 0.00018532799999999996, compute latency: 0.00018124799999999998, io overhead: 4.079999999999999e-06, kernel launch overhead: 0
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 0.0005614146953125
matmul total latency: 0.0005614146953125
weighted avg simd utilization: 0.998263713540922
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 1.0}
transformer latency: 0.0005614146953125
gpt3-175B decode latency per token: 0.0005614146953125
gpt3-175B decode total latency for 2048 tokens: 110.37862041599999
simulated latency: gpt3-175B_decode 110.37862041599999
Testing GPT-3 6.7B model prefill
Simulate Running on DRAM PIM
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram logical config: 1channels x 2ranks x 16banks x 8arrays x 1subarrays x 131072subarr_rows x 256cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 5.3718032786885255Tops
memory capacity: 8.0GB
peripheral area: 6.489116373236071mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
LLM model: gpt3-6.7B
simulating qkv: Matmul M=1024, K=4096, N=4096
qkv latency: 0.015585888, compute latency: 0.005112576000000001, io overhead: 8.272000000000001e-05
simulating q_mul_k: Batched Matmul BS=32 M=1024, K=128, N=1024
Batched Matmul: M=1024, K=128, N=1024, BS=32
BatchedMatmul latency: 9.1904e-05
q_mul_k latency: 9.1904e-05, compute latency: 7.014400000000001e-05, io overhead: 2.1760000000000002e-05
simulating a_mul_v: Batched Matmul BS=32 M=1024, K=1024, N=128
Batched Matmul: M=1024, K=1024, N=128, BS=32
BatchedMatmul latency: 5.3248e-05
a_mul_v latency: 5.3248e-05, compute latency: 4.0447999999999996e-05, io overhead: 1.28e-05
simulating h_matmul0: Matmul M=1024, K=4096, N=4096
h_matmul0 latency: 0.005195296, compute latency: 0.005112576000000001, io overhead: 8.272000000000001e-05
simulating h1_matmul1: Matmul M=1024, K=4096, N=16384
h1_matmul1 latency: 0.01860659199999999, compute latency: 0.017129472000000007, io overhead: 0.0014771199999999984
simulating h2_matmul2: Matmul M=1024, K=16384, N=4096
h2_matmul2 latency: 0.019792511999999984, compute latency: 0.017129472000000007, io overhead: 0.0026630400000000067
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 0.05932543999999997
matmul total latency: 0.05932543999999997
weighted avg simd utilization: 1.0
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 1.0}
gpt3-6.7B 32 layers prefill latency: 1.8984140799999991
simulated latency: gpt3-6.7B_prefill 1.8984140799999991
Testing GPT-3 6.7B model decode
Simulate Running on DRAM PIM
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram logical config: 1channels x 2ranks x 16banks x 8arrays x 1subarrays x 131072subarr_rows x 256cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 5.3718032786885255Tops
memory capacity: 8.0GB
peripheral area: 6.489116373236071mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
simulating qkv: Matmul M=1, K=4096, N=4096
qkv latency: 1.7903999999999997e-05, compute latency: 1.5743999999999997e-05, io overhead: 2.1600000000000005e-06, kernel launch overhead: 0
simulating q_mul_k:BatchedMatmul BS=32 M=1, K=128, N=1025
Batched Matmul: M=1, K=128, N=1025, BS=32
BatchedMatmul latency: 7.280390625e-07
q_mul_k latency: 7.280390625e-07, compute latency: 5.480195312500001e-07, io overhead: 1.8001953125000001e-07, kernel launch overhead: 0
simulating a_mul_v: BatchedMatmul BS=32 M=1, K=1025, N=128
Batched Matmul: M=1, K=1025, N=128, BS=32
BatchedMatmul latency: 5.7465625e-07
a_mul_v latency: 5.7465625e-07, compute latency: 4.1200000000000004e-07, io overhead: 1.6265624999999998e-07, kernel launch overhead: 0
simulating h_matmul0: Matmul M=1, K=4096, N=4096
h_matmul0 latency: 5.9679999999999994e-06, compute latency: 5.2479999999999996e-06, io overhead: 7.200000000000001e-07, kernel launch overhead: 0
simulating h1_matmul1: Matmul M=1, K=4096, N=16384
h1_matmul1 latency: 2.1183999999999996e-05, compute latency: 2.0223999999999998e-05, io overhead: 9.6e-07, kernel launch overhead: 0
simulating h2_matmul2: Matmul M=1, K=16384, N=4096
h2_matmul2 latency: 2.184e-05, compute latency: 2.048e-05, io overhead: 1.3600000000000001e-06, kernel launch overhead: 0
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 6.819869531249999e-05
matmul total latency: 6.819869531249999e-05
weighted avg simd utilization: 0.9857068125873697
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 1.0}
transformer latency: 6.819869531249999e-05
gpt3-6.7B decode latency per token: 6.819869531249999e-05
gpt3-6.7B decode total latency for 2048 tokens: 4.469469695999999
simulated latency: gpt3-6.7B_decode 4.469469695999999
Testing LLaMA 3.1 70B model prefill
Simulate Running on DRAM PIM
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram logical config: 1channels x 2ranks x 16banks x 8arrays x 1subarrays x 131072subarr_rows x 256cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 5.3718032786885255Tops
memory capacity: 8.0GB
peripheral area: 6.489116373236071mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
LLM model: Llama-3.1-70B
simulating q_proj: Matmul M=1024, K=8192, N=8192
q_proj latency: 0.018875008000000013, compute latency: 0.017481727999999967, io overhead: 0.0013932800000000063
simulating k_proj: Matmul M=1024, K=8192, N=1024
k_proj latency: 0.002648736, compute latency: 0.002556416, io overhead: 9.232e-05
simulating v_proj: Matmul M=1024, K=8192, N=1024
skipping v_proj simulation, using k_proj
v_proj latency: 0.002648736, compute latency: 0.002556416, io overhead: 9.232e-05
simulating q_mul_k: Batched_Matmul BS=64 M=1024, K=128, N=1024
Batched Matmul: M=1024, K=128, N=1024, BS=64
BatchedMatmul latency: 9.1904e-05
q_mul_k latency: 9.1904e-05, compute latency: 7.014400000000001e-05, io overhead: 2.1760000000000002e-05
simulating a_mul_v: Batched_Matmul BS=64 M=1024, K=1024, N=128
Batched Matmul: M=1024, K=1024, N=128, BS=64
BatchedMatmul latency: 5.3248e-05
a_mul_v latency: 5.3248e-05, compute latency: 4.0447999999999996e-05, io overhead: 1.28e-05
simulating h_matmul0: Matmul M=1024, K=8192, N=8192
h_matmul0 latency: 0.018875008000000013, compute latency: 0.017481727999999967, io overhead: 0.0013932800000000063
simulating h1_matmul1: Matmul M=1024, K=8192, N=28672
h1_matmul1 latency: 0.06224742399999998, compute latency: 0.05933670400000009, io overhead: 0.0029107199999999973
simulating h2_matmul2: Matmul M=1024, K=28672, N=8192
h2_matmul2 latency: 0.06409484799999995, compute latency: 0.059424768000000176, io overhead: 0.004670079999999986
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 0.16953491199999995
matmul total latency: 0.16953491199999995
weighted avg simd utilization: 1.0
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 1.0}
Llama-3.1-70B 80 layers prefill latency: 13.562792959999996
simulated latency: Llama-3.1-70B_prefill 13.562792959999996
Testing LLaMA 3.1 70B model decode
Simulate Running on DRAM PIM
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram logical config: 1channels x 2ranks x 16banks x 8arrays x 1subarrays x 131072subarr_rows x 256cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 5.3718032786885255Tops
memory capacity: 8.0GB
peripheral area: 6.489116373236071mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
simulating q_proj: Matmul M=1, K=8192, N=8192
q_proj latency: 2.1023999999999997e-05, compute latency: 2.0223999999999998e-05, io overhead: 8e-07
simulating k_proj: Matmul M=1, K=8192, N=1024
k_proj latency: 3.412e-06, compute latency: 2.752e-06, io overhead: 6.6e-07
simulating v_proj: Matmul M=1, K=8192, N=1024
skipping v_proj simulation, using k_proj
v_proj latency: 3.412e-06, compute latency: 2.752e-06, io overhead: 6.6e-07
simulating q_mul_k: Batched_Matmul BS=64 M=1, K=128, N=1025
Batched Matmul: M=1, K=128, N=1025, BS=64
BatchedMatmul latency: 7.280390625e-07
q_mul_k latency: 7.280390625e-07, compute latency: 5.480195312500001e-07, io overhead: 1.8001953125000001e-07
simulating a_mul_v: Batched_Matmul BS=64 M=1, K=1025, N=128
Batched Matmul: M=1, K=1025, N=128, BS=64
BatchedMatmul latency: 5.7465625e-07
a_mul_v latency: 5.7465625e-07, compute latency: 4.1200000000000004e-07, io overhead: 1.6265624999999998e-07
simulating h_matmul0: Matmul M=1, K=8192, N=8192
h_matmul0 latency: 2.1023999999999997e-05, compute latency: 2.0223999999999998e-05, io overhead: 8e-07
simulating h1_matmul1: Matmul M=1, K=8192, N=28672
h1_matmul1 latency: 7.1344e-05, compute latency: 7.0144e-05, io overhead: 1.2000000000000002e-06
simulating h2_matmul2: Matmul M=1, K=28672, N=8192
h2_matmul2 latency: 7.632000000000001e-05, compute latency: 7.167999999999999e-05, io overhead: 4.64e-06
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 0.0001978386953125
matmul total latency: 0.0001978386953125
weighted avg simd utilization: 0.9950728712001529
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 1.0}
Llama-3.1-70B decode latency per token: 0.0001978386953125
Llama-3.1-70B decode total latency for 2048 tokens: 32.41389184
simulated latency: Llama-3.1-70B_decode 32.41389184
Testing LLaMA 3.1 8B model prefill
Simulate Running on DRAM PIM
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram logical config: 1channels x 2ranks x 16banks x 8arrays x 1subarrays x 131072subarr_rows x 256cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 5.3718032786885255Tops
memory capacity: 8.0GB
peripheral area: 6.489116373236071mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
LLM model: Llama-3.1-8B
simulating q_proj: Matmul M=1024, K=4096, N=4096
q_proj latency: 0.005195296, compute latency: 0.005112576000000001, io overhead: 8.272000000000001e-05
simulating k_proj: Matmul M=1024, K=4096, N=1024
k_proj latency: 0.0013396479999999997, compute latency: 0.0012782079999999999, io overhead: 6.144e-05
simulating v_proj: Matmul M=1024, K=4096, N=1024
skipping v_proj simulation, using k_proj
v_proj latency: 0.0013396479999999997, compute latency: 0.0012782079999999999, io overhead: 6.144e-05
simulating q_mul_k: Batched_Matmul BS=32 M=1024, K=128, N=1024
Batched Matmul: M=1024, K=128, N=1024, BS=32
BatchedMatmul latency: 9.1904e-05
q_mul_k latency: 9.1904e-05, compute latency: 7.014400000000001e-05, io overhead: 2.1760000000000002e-05
simulating a_mul_v: Batched_Matmul BS=32 M=1024, K=1024, N=128
Batched Matmul: M=1024, K=1024, N=128, BS=32
BatchedMatmul latency: 5.3248e-05
a_mul_v latency: 5.3248e-05, compute latency: 4.0447999999999996e-05, io overhead: 1.28e-05
simulating h_matmul0: Matmul M=1024, K=4096, N=4096
h_matmul0 latency: 0.005195296, compute latency: 0.005112576000000001, io overhead: 8.272000000000001e-05
simulating h1_matmul1: Matmul M=1024, K=4096, N=14336
h1_matmul1 latency: 0.016444927999999984, compute latency: 0.014988288000000011, io overhead: 0.0014566399999999986
simulating h2_matmul2: Matmul M=1024, K=14336, N=4096
h2_matmul2 latency: 0.01736767999999999, compute latency: 0.01503231999999999, io overhead: 0.002335360000000007
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 0.04702764799999998
matmul total latency: 0.04702764799999998
weighted avg simd utilization: 1.0
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 1.0}
Llama-3.1-8B 32 layers prefill latency: 1.5048847359999993
simulated latency: Llama-3.1-8B_prefill 1.5048847359999993
Testing LLaMA 3.1 8B model decode
Simulate Running on DRAM PIM
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram logical config: 1channels x 2ranks x 16banks x 8arrays x 1subarrays x 131072subarr_rows x 256cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 5.3718032786885255Tops
memory capacity: 8.0GB
peripheral area: 6.489116373236071mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
simulating q_proj: Matmul M=1, K=4096, N=4096
q_proj latency: 5.9679999999999994e-06, compute latency: 5.2479999999999996e-06, io overhead: 7.200000000000001e-07
simulating k_proj: Matmul M=1, K=4096, N=1024
k_proj latency: 2.164e-06, compute latency: 1.504e-06, io overhead: 6.6e-07
simulating v_proj: Matmul M=1, K=4096, N=1024
skipping v_proj simulation, using k_proj
v_proj latency: 2.164e-06, compute latency: 1.504e-06, io overhead: 6.6e-07
simulating q_mul_k: Batched_Matmul BS=32 M=1, K=128, N=1025
Batched Matmul: M=1, K=128, N=1025, BS=32
BatchedMatmul latency: 7.280390625e-07
q_mul_k latency: 7.280390625e-07, compute latency: 5.480195312500001e-07, io overhead: 1.8001953125000001e-07
simulating a_mul_v: Batched_Matmul BS=32 M=1, K=1025, N=128
Batched Matmul: M=1, K=1025, N=128, BS=32
BatchedMatmul latency: 5.7465625e-07
a_mul_v latency: 5.7465625e-07, compute latency: 4.1200000000000004e-07, io overhead: 1.6265624999999998e-07
simulating h_matmul0: Matmul M=1, K=4096, N=4096
h_matmul0 latency: 5.9679999999999994e-06, compute latency: 5.2479999999999996e-06, io overhead: 7.200000000000001e-07
simulating h1_matmul1: Matmul M=1, K=4096, N=14336
h1_matmul1 latency: 1.8648e-05, compute latency: 1.7728e-05, io overhead: 9.200000000000001e-07
simulating h2_matmul2: Matmul M=1, K=14336, N=4096
h2_matmul2 latency: 2.1680000000000002e-05, compute latency: 2.048e-05, io overhead: 1.2e-06
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 5.7894695312500005e-05
matmul total latency: 5.7894695312500005e-05
weighted avg simd utilization: 0.9363538107678258
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 1.0}
Llama-3.1-8B decode latency per token: 5.7894695312500005e-05
Llama-3.1-8B decode total latency for 2048 tokens: 3.7941867520000003
simulated latency: Llama-3.1-8B_decode 3.7941867520000003
/home/siyuan/LLMCompass/exp_scripts/sensitivity
