Using config: configs/x16_8g.json
Running GEMM tests...
Test 1: M=1024, K=12288, N=12288
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 18.505643061989854Tops
memory capacity: 8.0GB
peripheral area: 16.512338092892996mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
Running mapping search...
find_simdram_mapping: Best mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: True
  Tile Mapping:  M: BD  N: A  K: RCS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
Running simulation...
--- Input Matmul Size --- M:1024, K:12288, N:12288
Maximum Array Tile Size: {'M': 8, 'K': 6144, 'N': 768}
get_arr_tile_stats: arr_latency=0.00037536959999999995, capacity_utilization=0.8828125
get_tile_stats: K_reduction_latency: 7.232e-05 = 7405568 / 102400000000.0
BD RCS ['A'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
2097152 = 1024 * 2048 * 1
get_tile_io_latency: data_volume=2097152, dup=['A'], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=2.048e-05 = 2097152 / 102400000000.0
get_tile_stats: tile_size: {'M': 1024, 'K': 2048, 'N': 3616}, arr_tile_size: {'M': 8, 'K': 1024, 'N': 226}, MK_dup: 1, KN_dup:1, MN_dup:1024, M_K_io_latency: 2.048e-05, K_N_io_latency: 0, M_N_io_latency: 3.616e-05, tile_compute_latency:0.00044768959999999996 = 0.00037536959999999995(arr_latency) + 7.232e-05(K_reduction_latency)
get_arr_tile_stats: arr_latency=0.0001497184, capacity_utilization=0.3515625
get_tile_stats: K_reduction_latency: 2.88e-05 = 2949120 / 102400000000.0
BD RCS ['A'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
2097152 = 1024 * 2048 * 1
get_tile_io_latency: data_volume=2097152, dup=['A'], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=2.048e-05 = 2097152 / 102400000000.0
get_tile_stats: tile_size: {'M': 1024, 'K': 2048, 'N': 1440}, arr_tile_size: {'M': 8, 'K': 1024, 'N': 90}, MK_dup: 1, KN_dup:1, MN_dup:1024, M_K_io_latency: 2.048e-05, K_N_io_latency: 0, M_N_io_latency: 1.44e-05, tile_compute_latency:0.0001785184 = 0.0001497184(arr_latency) + 2.88e-05(K_reduction_latency)
================ Strategy Summary ================
Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: True
  Tile Mapping:  M: BD  N: A  K: RCS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)

---------------- Tile Sizes ----------------------
| Tile_M      | Tile_N      | Tile_K      |
|-------------|-------------|-------------|
| 1024        | 3616        | 2048        |

| Arr_Tile_M  | Arr_Tile_N  | Arr_Tile_K  |
|-------------|-------------|-------------|
| 8           | 226         | 1024        |

--------------- Utilization ----------------------
| Row         | Col         | Array       | Bank        | Device      | Rank        | Channel     |
|-------------|-------------|-------------|-------------|-------------|-------------|-------------|
| 0.8828125   | 1.0         | 1           | 1           | 1           | 1           | 1           |

------------------ Latency -----------------------
| Total Latency        | 0.010618483199999999   cycles|
| Total Compute Latency | 0.009129523199999996   cycles|
| Total Array Latency  | 0.007654963199999997   cycles|
| Total Reduction Latency| 0.0014745600000000004  cycles|
| IO Latency           | 0.0014889600000000003  cycles|

----------- Hardware Requirements ---------------
| col_multicast        | False                 |
| col_broadcast        | False                 |
| broadcast            | {'C': False, 'R': False, 'B': False, 'A': True, 'S': False, 'D': False}|
| reduction            | {'C': True, 'R': True, 'B': False, 'A': False, 'S': True, 'D': False}|
==================================================

---------------- Debug Info -----------------------
| Remaining Tiles       |                         |
|-----------------------|-------------------------|
| M_remain              | 0                      |
| N_remain              | 1440                   |
| K_remain              | 0                      |

| Fully Partitioned #Tiles |                       |
|-------------------------|-----------------------|
| M_t                   | 1                      |
| N_t                   | 3                      |
| K_t                   | 6                      |

|------------------------|------------------------|
==================================================
Tiling utilization: {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
Column utilization: 1.0
Capacity utilization: 0.8828125
GEMM 1024x12288x12288 latency: 0.010618483199999999s
simulated latency: GEMM_1024x12288x12288 0.010618483199999999
roofline_model_simdram: total_ops=309237645312, total_data_movement=25165824, peak_flops=18505643061989.85, bandwidth=102400000000.0
roofline_model_simdram: compute_bound_time=0.0167104512, memory_bound_time=0.00024576
GEMM roofline latency: 0.0167104512ms
Results written to test_gemm_x16_8g.json_1024_12288_12288_simdram_ddr5_operandocality.csv
Test 2: M=2048, K=24576, N=24576
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 18.505643061989854Tops
memory capacity: 8.0GB
peripheral area: 16.512338092892996mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
Running mapping search...
find_simdram_mapping: Best mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: True
  Tile Mapping:  M: RB  N: A  K: DCS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
Running simulation...
--- Input Matmul Size --- M:2048, K:24576, N:24576
Maximum Array Tile Size: {'M': 64, 'K': 3072, 'N': 1536}
get_arr_tile_stats: arr_latency=0.0004052352, capacity_utilization=0.953125
get_tile_stats: K_reduction_latency: 7.808e-05 = 7995392 / 102400000000.0
RB DCS ['A'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
8388608 = 1024 * 8192 * 1
get_tile_io_latency: data_volume=8388608, dup=['A'], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=8.192e-05 = 8388608 / 102400000000.0
get_tile_stats: tile_size: {'M': 1024, 'K': 8192, 'N': 976}, arr_tile_size: {'M': 32, 'K': 1024, 'N': 61}, MK_dup: 1, KN_dup:1, MN_dup:1024, M_K_io_latency: 8.192e-05, K_N_io_latency: 0, M_N_io_latency: 9.76e-06, tile_compute_latency:0.0004833152 = 0.0004052352(arr_latency) + 7.808e-05(K_reduction_latency)
get_arr_tile_stats: arr_latency=7.339520000000001e-05, capacity_utilization=0.171875
get_tile_stats: K_reduction_latency: 1.408e-05 = 1441792 / 102400000000.0
RB DCS ['A'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
8388608 = 1024 * 8192 * 1
get_tile_io_latency: data_volume=8388608, dup=['A'], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=8.192e-05 = 8388608 / 102400000000.0
get_tile_stats: tile_size: {'M': 1024, 'K': 8192, 'N': 176}, arr_tile_size: {'M': 32, 'K': 1024, 'N': 11}, MK_dup: 1, KN_dup:1, MN_dup:1024, M_K_io_latency: 8.192e-05, K_N_io_latency: 0, M_N_io_latency: 1.76e-06, tile_compute_latency:8.747520000000001e-05 = 7.339520000000001e-05(arr_latency) + 1.408e-05(K_reduction_latency)
================ Strategy Summary ================
Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: True
  Tile Mapping:  M: RB  N: A  K: DCS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)

---------------- Tile Sizes ----------------------
| Tile_M      | Tile_N      | Tile_K      |
|-------------|-------------|-------------|
| 1024        | 976         | 8192        |

| Arr_Tile_M  | Arr_Tile_N  | Arr_Tile_K  |
|-------------|-------------|-------------|
| 32          | 61          | 1024        |

--------------- Utilization ----------------------
| Row         | Col         | Array       | Bank        | Device      | Rank        | Channel     |
|-------------|-------------|-------------|-------------|-------------|-------------|-------------|
| 0.953125    | 1.0         | 1           | 1           | 1           | 1           | 1           |

------------------ Latency -----------------------
| Total Latency        | 0.07597301119999991    cycles|
| Total Compute Latency | 0.07302213120000009    cycles|
| Total Array Latency  | 0.06122565119999994    cycles|
| Total Reduction Latency| 0.011796479999999984   cycles|
| IO Latency           | 0.0029508799999999934  cycles|

----------- Hardware Requirements ---------------
| col_multicast        | False                 |
| col_broadcast        | False                 |
| broadcast            | {'C': False, 'R': False, 'B': False, 'A': True, 'S': False, 'D': False}|
| reduction            | {'C': True, 'R': False, 'B': False, 'A': False, 'S': True, 'D': True}|
==================================================

---------------- Debug Info -----------------------
| Remaining Tiles       |                         |
|-----------------------|-------------------------|
| M_remain              | 0                      |
| N_remain              | 176                    |
| K_remain              | 0                      |

| Fully Partitioned #Tiles |                       |
|-------------------------|-----------------------|
| M_t                   | 2                      |
| N_t                   | 25                     |
| K_t                   | 3                      |

|------------------------|------------------------|
==================================================
Tiling utilization: {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
Column utilization: 1.0
Capacity utilization: 0.953125
GEMM 2048x24576x24576 latency: 0.07597301119999991s
simulated latency: GEMM_2048x24576x24576 0.07597301119999991
roofline_model_simdram: total_ops=2473901162496, total_data_movement=100663296, peak_flops=18505643061989.85, bandwidth=102400000000.0
roofline_model_simdram: compute_bound_time=0.1336836096, memory_bound_time=0.00098304
GEMM roofline latency: 0.1336836096ms
Results written to test_gemm_x16_8g.json_2048_24576_24576_simdram_ddr5_operandocality.csv
Test 3: M=1, K=12288, N=12288
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 18.505643061989854Tops
memory capacity: 8.0GB
peripheral area: 16.512338092892996mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
Running mapping search...
find_simdram_mapping: Best mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: True
  Tile Mapping:  M:   N: RAD  K: BCS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
Running simulation...
--- Input Matmul Size --- M:1, K:12288, N:12288
Maximum Array Tile Size: {'M': 1, 'K': 768, 'N': 48}
get_arr_tile_stats: arr_latency=1.03456e-05, capacity_utilization=0.0234375
get_tile_stats: K_reduction_latency: 1.92e-06 = 196608 / 102400000000.0
 BCS ['R', 'A', 'D'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
12288 = 1 * 12288 * 1
get_tile_io_latency: data_volume=196608, dup=['A'], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=1.92e-06 = 196608 / 102400000000.0
get_tile_stats: tile_size: {'M': 1, 'K': 12288, 'N': 12288}, arr_tile_size: {'M': 1, 'K': 768, 'N': 48}, MK_dup: 1, KN_dup:1, MN_dup:768, M_K_io_latency: 1.92e-06, K_N_io_latency: 0, M_N_io_latency: 1.2e-07, tile_compute_latency:1.22656e-05 = 1.03456e-05(arr_latency) + 1.92e-06(K_reduction_latency)
================ Strategy Summary ================
Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: True
  Tile Mapping:  M:   N: RAD  K: BCS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)

---------------- Tile Sizes ----------------------
| Tile_M      | Tile_N      | Tile_K      |
|-------------|-------------|-------------|
| 1           | 12288       | 12288       |

| Arr_Tile_M  | Arr_Tile_N  | Arr_Tile_K  |
|-------------|-------------|-------------|
| 1           | 48          | 768         |

--------------- Utilization ----------------------
| Row         | Col         | Array       | Bank        | Device      | Rank        | Channel     |
|-------------|-------------|-------------|-------------|-------------|-------------|-------------|
| 0.0234375   | 0.75        | 1           | 1           | 1           | 1           | 1           |

------------------ Latency -----------------------
| Total Latency        | 1.44256e-05            cycles|
| Total Compute Latency | 1.22656e-05            cycles|
| Total Array Latency  | 1.03456e-05            cycles|
| Total Reduction Latency| 1.92e-06               cycles|
| IO Latency           | 2.16e-06               cycles|

----------- Hardware Requirements ---------------
| col_multicast        | False                 |
| col_broadcast        | False                 |
| broadcast            | {'C': False, 'R': True, 'B': False, 'A': True, 'S': False, 'D': True}|
| reduction            | {'C': True, 'R': False, 'B': True, 'A': False, 'S': True, 'D': False}|
==================================================

---------------- Debug Info -----------------------
| Remaining Tiles       |                         |
|-----------------------|-------------------------|
| M_remain              | 0                      |
| N_remain              | 0                      |
| K_remain              | 0                      |

| Fully Partitioned #Tiles |                       |
|-------------------------|-----------------------|
| M_t                   | 1                      |
| N_t                   | 1                      |
| K_t                   | 1                      |

|------------------------|------------------------|
==================================================
Tiling utilization: {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
Column utilization: 0.75
Capacity utilization: 0.0234375
GEMM 1x12288x12288 latency: 1.44256e-05s
simulated latency: GEMM_1x12288x12288 1.44256e-05
roofline_model_simdram: total_ops=301989888, total_data_movement=24576, peak_flops=18505643061989.85, bandwidth=102400000000.0
roofline_model_simdram: compute_bound_time=1.63188e-05, memory_bound_time=2.4e-07
GEMM roofline latency: 1.63188e-05ms
Results written to test_gemm_x16_8g.json_1_12288_12288_simdram_ddr5_operandocality.csv
Test 4: M=1, K=24576, N=24576
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 18.505643061989854Tops
memory capacity: 8.0GB
peripheral area: 16.512338092892996mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
Running mapping search...
find_simdram_mapping: Best mapping: Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: True
  Tile Mapping:  M:   N: RBA  K: DCS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)
Running simulation...
--- Input Matmul Size --- M:1, K:24576, N:24576
Maximum Array Tile Size: {'M': 1, 'K': 3072, 'N': 48}
get_arr_tile_stats: arr_latency=1.03456e-05, capacity_utilization=0.0234375
get_tile_stats: K_reduction_latency: 1.92e-06 = 196608 / 102400000000.0
 DCS ['R', 'B', 'A'] {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
8192 = 1 * 8192 * 1
get_tile_io_latency: data_volume=16384, dup=['B', 'A'], simd_utilization={'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
get_tile_io_latency: latency=2.56e-06 = 16384 / 6400000000.0
get_tile_stats: tile_size: {'M': 1, 'K': 8192, 'N': 24576}, arr_tile_size: {'M': 1, 'K': 1024, 'N': 48}, MK_dup: 1, KN_dup:1, MN_dup:1024, M_K_io_latency: 2.56e-06, K_N_io_latency: 0, M_N_io_latency: 2.4e-07, tile_compute_latency:1.22656e-05 = 1.03456e-05(arr_latency) + 1.92e-06(K_reduction_latency)
================ Strategy Summary ================
Strategy(
  Loop Order: mkn  PE Enabled: True  Broadcast: AB
  Array Multicast: False
  Column Popcount: True
  Tile Mapping:  M:   N: RBA  K: DCS  Array Mapping:  R: MN  C: K
  Weight Resident: True
  Input Resident: False
  Output Resident: False
)

---------------- Tile Sizes ----------------------
| Tile_M      | Tile_N      | Tile_K      |
|-------------|-------------|-------------|
| 1           | 24576       | 8192        |

| Arr_Tile_M  | Arr_Tile_N  | Arr_Tile_K  |
|-------------|-------------|-------------|
| 1           | 48          | 1024        |

--------------- Utilization ----------------------
| Row         | Col         | Array       | Bank        | Device      | Rank        | Channel     |
|-------------|-------------|-------------|-------------|-------------|-------------|-------------|
| 0.0234375   | 1.0         | 1           | 1           | 1           | 1           | 1           |

------------------ Latency -----------------------
| Total Latency        | 4.4956799999999996e-05 cycles|
| Total Compute Latency | 3.67968e-05            cycles|
| Total Array Latency  | 3.10368e-05            cycles|
| Total Reduction Latency| 5.759999999999999e-06  cycles|
| IO Latency           | 8.159999999999998e-06  cycles|

----------- Hardware Requirements ---------------
| col_multicast        | False                 |
| col_broadcast        | False                 |
| broadcast            | {'C': False, 'R': True, 'B': True, 'A': True, 'S': False, 'D': False}|
| reduction            | {'C': True, 'R': False, 'B': False, 'A': False, 'S': True, 'D': True}|
==================================================

---------------- Debug Info -----------------------
| Remaining Tiles       |                         |
|-----------------------|-------------------------|
| M_remain              | 0                      |
| N_remain              | 0                      |
| K_remain              | 0                      |

| Fully Partitioned #Tiles |                       |
|-------------------------|-----------------------|
| M_t                   | 1                      |
| N_t                   | 1                      |
| K_t                   | 3                      |

|------------------------|------------------------|
==================================================
Tiling utilization: {'C': 1, 'R': 1, 'B': 1, 'A': 1, 'S': 1, 'D': 1}
Column utilization: 1.0
Capacity utilization: 0.0234375
GEMM 1x24576x24576 latency: 4.4956799999999996e-05s
simulated latency: GEMM_1x24576x24576 4.4956799999999996e-05
roofline_model_simdram: total_ops=1207959552, total_data_movement=49152, peak_flops=18505643061989.85, bandwidth=102400000000.0
roofline_model_simdram: compute_bound_time=6.52752e-05, memory_bound_time=4.8e-07
GEMM roofline latency: 6.52752e-05ms
Results written to test_gemm_x16_8g.json_1_24576_24576_simdram_ddr5_operandocality.csv
Running LLM tests...
Testing GPT-3 175B model prefill
Simulate Running on DRAM PIM
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 18.505643061989854Tops
memory capacity: 8.0GB
peripheral area: 16.512338092892996mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
LLM model: gpt3-175B
simulating qkv: Matmul M=1024, K=12288, N=12288
qkv latency: 0.031855449599999995, compute latency: 0.009129523199999996, io overhead: 0.0014889600000000003
simulating q_mul_k: Batched Matmul BS=96 M=1024, K=128, N=1024
Batched Matmul: M=1024, K=128, N=1024, BS=96
BatchedMatmul latency: 8.54848e-05
q_mul_k latency: 8.54848e-05, compute latency: 6.37248e-05, io overhead: 2.1760000000000002e-05
simulating a_mul_v: Batched Matmul BS=96 M=1024, K=1024, N=128
Batched Matmul: M=1024, K=1024, N=128, BS=96
BatchedMatmul latency: 2.11072e-05
a_mul_v latency: 2.11072e-05, compute latency: 8.307199999999999e-06, io overhead: 1.28e-05
simulating h_matmul0: Matmul M=1024, K=12288, N=12288
h_matmul0 latency: 0.010618483199999999, compute latency: 0.009129523199999996, io overhead: 0.0014889600000000003
simulating h1_matmul1: Matmul M=1024, K=12288, N=49152
h1_matmul1 latency: 0.04206444800000003, compute latency: 0.03651340799999998, io overhead: 0.005551039999999995
simulating h2_matmul2: Matmul M=1024, K=49152, N=12288
h2_matmul2 latency: 0.03761986559999996, compute latency: 0.03651106560000003, io overhead: 0.0011087999999999996
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 0.12226483839999999
matmul total latency: 0.12226483839999999
weighted avg simd utilization: 0.9993882198596191
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 1.0}
gpt3-175B 96 layers prefill latency: 11.737424486399998
simulated latency: gpt3-175B_prefill 11.737424486399998
Testing GPT-3 175B model decode
Simulate Running on DRAM PIM
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 18.505643061989854Tops
memory capacity: 8.0GB
peripheral area: 16.512338092892996mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
simulating qkv: Matmul M=1, K=12288, N=12288
qkv latency: 4.32768e-05, compute latency: 3.67968e-05, io overhead: 6.480000000000001e-06, kernel launch overhead: 0
simulating q_mul_k:BatchedMatmul BS=96 M=1, K=128, N=1025
Batched Matmul: M=1, K=128, N=1025, BS=96
BatchedMatmul latency: 8.218625e-07
q_mul_k latency: 8.218625e-07, compute latency: 6.298312500000001e-07, io overhead: 1.9203125e-07, kernel launch overhead: 0
simulating a_mul_v: BatchedMatmul BS=96 M=1, K=1025, N=128
Batched Matmul: M=1, K=1025, N=128, BS=96
BatchedMatmul latency: 7.203781250000001e-07
a_mul_v latency: 7.203781250000001e-07, compute latency: 6.378000000000001e-07, io overhead: 8.2578125e-08, kernel launch overhead: 0
simulating h_matmul0: Matmul M=1, K=12288, N=12288
h_matmul0 latency: 1.44256e-05, compute latency: 1.22656e-05, io overhead: 2.16e-06, kernel launch overhead: 0
simulating h1_matmul1: Matmul M=1, K=12288, N=49152
h1_matmul1 latency: 5.07712e-05, compute latency: 4.78912e-05, io overhead: 2.88e-06, kernel launch overhead: 0
simulating h2_matmul2: Matmul M=1, K=49152, N=12288
h2_matmul2 latency: 4.47168e-05, compute latency: 3.67968e-05, io overhead: 7.92e-06, kernel launch overhead: 0
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 0.000154732640625
matmul total latency: 0.000154732640625
weighted avg simd utilization: 0.8152551472487283
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 0.9980081873077645}
transformer latency: 0.000154732640625
gpt3-175B decode latency per token: 0.000154732640625
gpt3-175B decode total latency for 2048 tokens: 30.421675008
simulated latency: gpt3-175B_decode 30.421675008
Testing GPT-3 6.7B model prefill
Simulate Running on DRAM PIM
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 18.505643061989854Tops
memory capacity: 8.0GB
peripheral area: 16.512338092892996mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
LLM model: gpt3-6.7B
simulating qkv: Matmul M=1024, K=4096, N=4096
qkv latency: 0.003413376, compute latency: 0.001014912, io overhead: 0.00012288
simulating q_mul_k: Batched Matmul BS=32 M=1024, K=128, N=1024
Batched Matmul: M=1024, K=128, N=1024, BS=32
BatchedMatmul latency: 8.54848e-05
q_mul_k latency: 8.54848e-05, compute latency: 6.37248e-05, io overhead: 2.1760000000000002e-05
simulating a_mul_v: Batched Matmul BS=32 M=1024, K=1024, N=128
Batched Matmul: M=1024, K=1024, N=128, BS=32
BatchedMatmul latency: 2.11072e-05
a_mul_v latency: 2.11072e-05, compute latency: 8.307199999999999e-06, io overhead: 1.28e-05
simulating h_matmul0: Matmul M=1024, K=4096, N=4096
h_matmul0 latency: 0.001137792, compute latency: 0.001014912, io overhead: 0.00012288
simulating h1_matmul1: Matmul M=1024, K=4096, N=16384
h1_matmul1 latency: 0.0046089856, compute latency: 0.0040573056, io overhead: 0.00055168
simulating h2_matmul2: Matmul M=1024, K=16384, N=4096
h2_matmul2 latency: 0.004262655999999999, compute latency: 0.004057695999999998, io overhead: 0.00020496000000000002
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 0.013529401600000001
matmul total latency: 0.013529401600000001
weighted avg simd utilization: 0.9944713593245689
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 1.0}
gpt3-6.7B 32 layers prefill latency: 0.43294085120000003
simulated latency: gpt3-6.7B_prefill 0.43294085120000003
Testing GPT-3 6.7B model decode
Simulate Running on DRAM PIM
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 18.505643061989854Tops
memory capacity: 8.0GB
peripheral area: 16.512338092892996mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
simulating qkv: Matmul M=1, K=4096, N=4096
qkv latency: 1.11888e-05, compute latency: 7.108799999999999e-06, io overhead: 4.08e-06, kernel launch overhead: 0
simulating q_mul_k:BatchedMatmul BS=32 M=1, K=128, N=1025
Batched Matmul: M=1, K=128, N=1025, BS=32
BatchedMatmul latency: 8.218625e-07
q_mul_k latency: 8.218625e-07, compute latency: 6.298312500000001e-07, io overhead: 1.9203125e-07, kernel launch overhead: 0
simulating a_mul_v: BatchedMatmul BS=32 M=1, K=1025, N=128
Batched Matmul: M=1, K=1025, N=128, BS=32
BatchedMatmul latency: 7.203781250000001e-07
a_mul_v latency: 7.203781250000001e-07, compute latency: 6.378000000000001e-07, io overhead: 8.2578125e-08, kernel launch overhead: 0
simulating h_matmul0: Matmul M=1, K=4096, N=4096
h_matmul0 latency: 3.7296e-06, compute latency: 2.3695999999999997e-06, io overhead: 1.3600000000000001e-06, kernel launch overhead: 0
simulating h1_matmul1: Matmul M=1, K=4096, N=16384
h1_matmul1 latency: 9.907199999999999e-06, compute latency: 8.307199999999999e-06, io overhead: 1.6e-06, kernel launch overhead: 0
simulating h2_matmul2: Matmul M=1, K=16384, N=4096
h2_matmul2 latency: 6.9888e-06, compute latency: 4.3488e-06, io overhead: 2.64e-06, kernel launch overhead: 0
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 3.3356640625e-05
matmul total latency: 3.3356640625e-05
weighted avg simd utilization: 0.5838771936260876
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 0.9907605073015351}
transformer latency: 3.3356640625e-05
gpt3-6.7B decode latency per token: 3.3356640625e-05
gpt3-6.7B decode total latency for 2048 tokens: 2.1860608
simulated latency: gpt3-6.7B_decode 2.1860608
Testing LLaMA 3.1 70B model prefill
Simulate Running on DRAM PIM
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 18.505643061989854Tops
memory capacity: 8.0GB
peripheral area: 16.512338092892996mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
LLM model: Llama-3.1-70B
simulating q_proj: Matmul M=1024, K=8192, N=8192
q_proj latency: 0.004222396799999998, compute latency: 0.0040584767999999995, io overhead: 0.00016392000000000002
simulating k_proj: Matmul M=1024, K=8192, N=1024
k_proj latency: 0.000600096, compute latency: 0.000507456, io overhead: 9.264e-05
simulating v_proj: Matmul M=1024, K=8192, N=1024
skipping v_proj simulation, using k_proj
v_proj latency: 0.000600096, compute latency: 0.000507456, io overhead: 9.264e-05
simulating q_mul_k: Batched_Matmul BS=64 M=1024, K=128, N=1024
Batched Matmul: M=1024, K=128, N=1024, BS=64
BatchedMatmul latency: 8.54848e-05
q_mul_k latency: 8.54848e-05, compute latency: 6.37248e-05, io overhead: 2.1760000000000002e-05
simulating a_mul_v: Batched_Matmul BS=64 M=1024, K=1024, N=128
Batched Matmul: M=1024, K=1024, N=128, BS=64
BatchedMatmul latency: 2.11072e-05
a_mul_v latency: 2.11072e-05, compute latency: 8.307199999999999e-06, io overhead: 1.28e-05
simulating h_matmul0: Matmul M=1024, K=8192, N=8192
h_matmul0 latency: 0.004222396799999998, compute latency: 0.0040584767999999995, io overhead: 0.00016392000000000002
simulating h1_matmul1: Matmul M=1024, K=8192, N=28672
h1_matmul1 latency: 0.0145709376, compute latency: 0.014198617600000006, io overhead: 0.0003723199999999997
simulating h2_matmul2: Matmul M=1024, K=28672, N=8192
h2_matmul2 latency: 0.016597251199999986, compute latency: 0.016228051200000003, io overhead: 0.0003692000000000008
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 0.04091976639999998
matmul total latency: 0.04091976639999998
weighted avg simd utilization: 0.9474714596611188
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 1.0}
Llama-3.1-70B 80 layers prefill latency: 3.2735813119999984
simulated latency: Llama-3.1-70B_prefill 3.2735813119999984
Testing LLaMA 3.1 70B model decode
Simulate Running on DRAM PIM
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 18.505643061989854Tops
memory capacity: 8.0GB
peripheral area: 16.512338092892996mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
simulating q_proj: Matmul M=1, K=8192, N=8192
q_proj latency: 7.0688e-06, compute latency: 4.3488e-06, io overhead: 2.7200000000000002e-06
simulating k_proj: Matmul M=1, K=8192, N=1024
k_proj latency: 2.6799999999999998e-06, compute latency: 1.38e-06, io overhead: 1.2999999999999998e-06
simulating v_proj: Matmul M=1, K=8192, N=1024
skipping v_proj simulation, using k_proj
v_proj latency: 2.6799999999999998e-06, compute latency: 1.38e-06, io overhead: 1.2999999999999998e-06
simulating q_mul_k: Batched_Matmul BS=64 M=1, K=128, N=1025
Batched Matmul: M=1, K=128, N=1025, BS=64
BatchedMatmul latency: 8.218625e-07
q_mul_k latency: 8.218625e-07, compute latency: 6.298312500000001e-07, io overhead: 1.9203125e-07
simulating a_mul_v: Batched_Matmul BS=64 M=1, K=1025, N=128
Batched Matmul: M=1, K=1025, N=128, BS=64
BatchedMatmul latency: 7.203781250000001e-07
a_mul_v latency: 7.203781250000001e-07, compute latency: 6.378000000000001e-07, io overhead: 8.2578125e-08
simulating h_matmul0: Matmul M=1, K=8192, N=8192
h_matmul0 latency: 7.0688e-06, compute latency: 4.3488e-06, io overhead: 2.7200000000000002e-06
simulating h1_matmul1: Matmul M=1, K=8192, N=28672
h1_matmul1 latency: 1.73648e-05, compute latency: 1.4244800000000001e-05, io overhead: 3.1199999999999998e-06
simulating h2_matmul2: Matmul M=1, K=28672, N=8192
h2_matmul2 latency: 1.8624e-05, compute latency: 1.6224e-05, io overhead: 2.4000000000000003e-06
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 5.7028640625e-05
matmul total latency: 5.7028640625e-05
weighted avg simd utilization: 0.886449004620982
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 0.9945957253386664}
Llama-3.1-70B decode latency per token: 5.7028640625e-05
Llama-3.1-70B decode total latency for 2048 tokens: 9.343572479999999
simulated latency: Llama-3.1-70B_decode 9.343572479999999
Testing LLaMA 3.1 8B model prefill
Simulate Running on DRAM PIM
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 18.505643061989854Tops
memory capacity: 8.0GB
peripheral area: 16.512338092892996mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
LLM model: Llama-3.1-8B
simulating q_proj: Matmul M=1024, K=4096, N=4096
q_proj latency: 0.001137792, compute latency: 0.001014912, io overhead: 0.00012288
simulating k_proj: Matmul M=1024, K=4096, N=1024
k_proj latency: 0.0003155584, compute latency: 0.0002541184, io overhead: 6.144000000000001e-05
simulating v_proj: Matmul M=1024, K=4096, N=1024
skipping v_proj simulation, using k_proj
v_proj latency: 0.0003155584, compute latency: 0.0002541184, io overhead: 6.144000000000001e-05
simulating q_mul_k: Batched_Matmul BS=32 M=1024, K=128, N=1024
Batched Matmul: M=1024, K=128, N=1024, BS=32
BatchedMatmul latency: 8.54848e-05
q_mul_k latency: 8.54848e-05, compute latency: 6.37248e-05, io overhead: 2.1760000000000002e-05
simulating a_mul_v: Batched_Matmul BS=32 M=1024, K=1024, N=128
Batched Matmul: M=1024, K=1024, N=128, BS=32
BatchedMatmul latency: 2.11072e-05
a_mul_v latency: 2.11072e-05, compute latency: 8.307199999999999e-06, io overhead: 1.28e-05
simulating h_matmul0: Matmul M=1024, K=4096, N=4096
h_matmul0 latency: 0.001137792, compute latency: 0.001014912, io overhead: 0.00012288
simulating h1_matmul1: Matmul M=1024, K=4096, N=14336
h1_matmul1 latency: 0.004055769599999999, compute latency: 0.0035498495999999997, io overhead: 0.0005059200000000001
simulating h2_matmul2: Matmul M=1024, K=14336, N=4096
h2_matmul2 latency: 0.0037774719999999996, compute latency: 0.0035521919999999996, io overhead: 0.00022528000000000007
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 0.0108465344
matmul total latency: 0.0108465344
weighted avg simd utilization: 0.9931038618196795
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 1.0}
Llama-3.1-8B 32 layers prefill latency: 0.3470891008
simulated latency: Llama-3.1-8B_prefill 0.3470891008
Testing LLaMA 3.1 8B model decode
Simulate Running on DRAM PIM
compute module:
simdram config: 1channels x 2ranks x 16banks x 16arrays x 1subarrays x 16384subarr_rows x 1024cols x 8devices, with_PE: True
simdram bw: 102.4GB/s
simdram internal bw: 37025.988700564965GB/s
simdram ops: 18.505643061989854Tops
memory capacity: 8.0GB
peripheral area: 16.512338092892996mm^2
dram area: 264.0mm^2

memory module: N/A
io module: N/A
simulating q_proj: Matmul M=1, K=4096, N=4096
q_proj latency: 3.7296e-06, compute latency: 2.3695999999999997e-06, io overhead: 1.3600000000000001e-06
simulating k_proj: Matmul M=1, K=4096, N=1024
k_proj latency: 2.04e-06, compute latency: 1.38e-06, io overhead: 6.6e-07
simulating v_proj: Matmul M=1, K=4096, N=1024
skipping v_proj simulation, using k_proj
v_proj latency: 2.04e-06, compute latency: 1.38e-06, io overhead: 6.6e-07
simulating q_mul_k: Batched_Matmul BS=32 M=1, K=128, N=1025
Batched Matmul: M=1, K=128, N=1025, BS=32
BatchedMatmul latency: 8.218625e-07
q_mul_k latency: 8.218625e-07, compute latency: 6.298312500000001e-07, io overhead: 1.9203125e-07
simulating a_mul_v: Batched_Matmul BS=32 M=1, K=1025, N=128
Batched Matmul: M=1, K=1025, N=128, BS=32
BatchedMatmul latency: 7.203781250000001e-07
a_mul_v latency: 7.203781250000001e-07, compute latency: 6.378000000000001e-07, io overhead: 8.2578125e-08
simulating h_matmul0: Matmul M=1, K=4096, N=4096
h_matmul0 latency: 3.7296e-06, compute latency: 2.3695999999999997e-06, io overhead: 1.3600000000000001e-06
simulating h1_matmul1: Matmul M=1, K=4096, N=14336
h1_matmul1 latency: 8.877600000000001e-06, compute latency: 7.3176e-06, io overhead: 1.5599999999999999e-06
simulating h2_matmul2: Matmul M=1, K=14336, N=4096
h2_matmul2 latency: 6.6687999999999996e-06, compute latency: 4.3488e-06, io overhead: 2.3200000000000002e-06
finish matmul simulation
matmul total overhead: 0
matmul total latency w/o overhead: 2.8627840625e-05
matmul total latency: 2.8627840625e-05
weighted avg simd utilization: 0.5273950597494269
weighted avg tiling utilization: {'C': 1.0, 'R': 1.0, 'B': 1.0, 'A': 1.0, 'S': 1.0, 'D': 0.9892343106999534}
Llama-3.1-8B decode latency per token: 2.8627840625e-05
Llama-3.1-8B decode total latency for 2048 tokens: 1.8761541632
simulated latency: Llama-3.1-8B_decode 1.8761541632
