python -m siyuan_test.test_llm_drampim --config configs/x16\{\'C\'\:\ 10\,\ \'R\'\:\ 4\,\ \'B\'\:\ 16\,\ \'A\'\:\ 16\,\ \'S\'\:\ 1\,\ \'D\'\:\ 8\}16384x1024.json --model LLM_hyper/llama-3.1-70b.json --decode --pipelined